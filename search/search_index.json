{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "getting-started/", "title": "Getting Started", "text": "<p>There are multiple ways to deploy Lakekeeper. Our self-contained examples are the easiest way to get started and deploy everything you need (including S3, Query Engines, Jupyter, ...). By default, compute outside of the docker network cannot access the example Warehouses due to docker networking.</p> <p>If you have your own Storage (e.g. S3) available, you can deploy Lakekeeper using docker compose, deploy on Kubernetes, deploy the pre-build Binary directly or compile Lakekeeper yourself.</p> <p>Lakekeeper is currently only compatible with Postgres &gt;= 15.</p>"}, {"location": "getting-started/#deployment", "title": "Deployment", "text": ""}, {"location": "getting-started/#option-1-examples", "title": "Option 1: \ud83d\udc33 Examples", "text": "<p>Note</p> <p>Our docker compose examples are not designed to be used with compute outside of the docker network (e.g. external Spark).</p> <p>All docker compose examples come with batteries included (Identity Provider, Storage (S3), Query Engines, Jupyter) but are not accessible (by default) for compute outside of the docker network. To use Lakekeeper with external tools outside of the docker network, please check Option 2: Docker Compose</p> \ud83d\udc33 With Authentication &amp; Authorization\ud83d\udc33 Unsecured <pre><code>git clone https://github.com/lakekeeper/lakekeeper\ncd examples/access-control\ndocker-compose up -d\n</code></pre> <pre><code>git clone https://github.com/lakekeeper/lakekeeper\ncd examples/minimal\ndocker-compose up -d\n</code></pre> <p>Then open your browser and head to <code>localhost:8888</code> to load the example Jupyter notebooks or head to <code>localhost:8181</code> for the Lakekeeper UI.</p>"}, {"location": "getting-started/#option-2-docker-compose", "title": "Option 2: \ud83d\udc33 Docker Compose", "text": "<p>For a Docker-Compose deployment that is used with external object storage, and external Identity Providers, you can use the <code>docker-compose</code> Setup. Please also check the Examples and our User Guides for additional information on customization.</p> <p>While you can start the \"\ud83d\udc33 Unsecured\" variant without any external dependencies, you will need at least an external object store (S3, ADLS, GCS) to create a Warehouse.</p> \ud83d\udc33 Unsecured\ud83d\udc33 Authentication &amp; Authorization <pre><code>git clone https://github.com/lakekeeper/lakekeeper\ncd docker-compose\ndocker-compose up -d\n</code></pre> <p>Please follow the Authentication Guide to prepare your Identity Provider. Additional environment variables might be required.</p> <pre><code>git clone https://github.com/lakekeeper/lakekeeper\ncd docker-compose\nexport LAKEKEEPER__OPENID_PROVIDER_URI=... (required)\nexport LAKEKEEPER__OPENID_AUDIENCE=... (recommended)\nexport LAKEKEEPER__UI__OPENID_CLIENT_ID=... (required if UI is used)\nexport LAKEKEEPER__UI__OPENID_SCOPE=... (typically required if UI is used)\ndocker compose -f docker-compose.yaml -f openfga-overlay.yaml up\n</code></pre>"}, {"location": "getting-started/#option-3-kubernetes", "title": "Option 3: \u2638\ufe0f Kubernetes", "text": "<p>We recommend deploying the catalog on Kubernetes using our Helm Chart. Please check the Helm Chart's documentation for possible values. To enable Authentication and Authorization, an external identity provider is required.</p> <p>A community driven Kubernetes Operator is currently in development.</p>"}, {"location": "getting-started/#option-4-binary", "title": "Option 4: \u2699\ufe0f Binary", "text": "<p>For single node deployments, you can also download the Binary for your architecture from Github Releases. A basic configuration via environment variables would look like this:</p> <pre><code>export LAKEKEEPER__PG_DATABASE_URL_READ=\"postgres://postgres_user:postgres_urlencoded_password@hostname:5432/catalog_database\"\nexport LAKEKEEPER__PG_DATABASE_URL_WRITE=\"postgres://postgres_user:postgres_urlencoded_password@hostname:5432/catalog_database\"\nexport LAKEKEEPER__PG_ENCRYPTION_KEY=\"MySecretEncryptionKeyThatIBetterNotLoose\"\n\n./lakekeeper migrate\n./lakekeeper serve\n</code></pre> <p>To expose Lakekeeper behind a reverse proxy, most deployments also set: <pre><code>export LAKEKEEPER__BASE_URI=&lt;https://&lt;Url-where-Lakekeeper-is-externally-reachable&gt;\n</code></pre> The default <code>LAKEKEEPER__BASE_URI</code> is <code>https://localhost:8181</code>.</p>"}, {"location": "getting-started/#option-5-build-from-sources", "title": "Option 5: \ud83d\udc68\u200d\ud83d\udcbb Build from Sources", "text": "<p>To customize Lakekeeper, for example to connect to your own Authorization system, you might want to build the binary yourself. Please check the Developer Guide for more information. </p>"}, {"location": "getting-started/#first-steps", "title": "First Steps", "text": "<p>Now that the catalog is up-and-running, the following endpoints are available:</p> <ol> <li><code>&lt;LAKEKEEPER__BASE_URI&gt;/ui/</code> - the UI - by default: http://localhost:8181/ui/</li> <li><code>&lt;LAKEKEEPER__BASE_URI&gt;/catalog</code> is the Iceberg REST API</li> <li><code>&lt;LAKEKEEPER__BASE_URI&gt;/management</code> contains the management API</li> <li><code>&lt;LAKEKEEPER__BASE_URI&gt;/swagger-ui</code> hosts Swagger to inspect the API specifications</li> </ol>"}, {"location": "getting-started/#bootstrapping", "title": "Bootstrapping", "text": "<p>Our self-contained docker compose examples are already bootstrapped and require no further actions.</p> <p>After the initial deployment, Lakekeeper needs to be bootstrapped. This can be done via the UI or the bootstrap endpoint. Among others, bootstrapping sets the initial administrator of Lakekeeper and creates the first project. Please find more information on bootstrapping in the Bootstrap Docs.</p>"}, {"location": "getting-started/#creating-a-warehouse", "title": "Creating a Warehouse", "text": "<p>Now that the server is running, we need to create a new warehouse. We recommend to do this via the UI.</p> <p></p> Create a Warehouse via UI <p></p> <p>Alternatively, we can use the REST-API directly. For an S3 backed warehouse, create a file called <code>create-warehouse-request.json</code>:</p> <pre><code>{\n  \"warehouse-name\": \"my-warehouse\",\n  \"storage-profile\": {\n    \"type\": \"s3\",\n    \"bucket\": \"my-example-bucket\",\n    \"key-prefix\": \"optional/path/in/bucket\",\n    \"region\": \"us-east-1\",\n    \"sts-role-arn\": \"arn:aws:iam::....:role/....\",\n    \"sts-enabled\": true,\n    \"flavor\": \"aws\"\n  },\n  \"storage-credential\": {\n    \"type\": \"s3\",\n    \"credential-type\": \"access-key\",\n    \"aws-access-key-id\": \"...\",\n    \"aws-secret-access-key\": \"...\"\n  }\n}\n</code></pre> <p>We now create a new Warehouse by POSTing the request to the management API:</p> <pre><code>curl -X POST http://localhost:8181/management/v1/warehouse -H \"Content-Type: application/json\" -d @create-warehouse-request.json\n</code></pre> <p>If you want to use a different storage backend, see the Storage Guide for example configurations.</p>"}, {"location": "getting-started/#connect-compute", "title": "Connect Compute", "text": "<p>That's it - we can now use the catalog:</p> <pre><code>import pandas as pd\nimport pyspark\n\nSPARK_VERSION = pyspark.__version__\nSPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\nICEBERG_VERSION = \"1.6.1\"\n\n# if you use adls as storage backend, you need iceberg-azure instead of iceberg-aws-bundle\nconfiguration = {\n    \"spark.jars.packages\": f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION},org.apache.iceberg:iceberg-azure-bundle:{ICEBERG_VERSION},org.apache.iceberg:iceberg-gcp-bundle:{ICEBERG_VERSION}\",\n    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n    \"spark.sql.defaultCatalog\": \"demo\",\n    \"spark.sql.catalog.demo\": \"org.apache.iceberg.spark.SparkCatalog\",\n    \"spark.sql.catalog.demo.catalog-impl\": \"org.apache.iceberg.rest.RESTCatalog\",\n    \"spark.sql.catalog.demo.uri\": \"http://localhost:8181/catalog/\",\n    \"spark.sql.catalog.demo.token\": \"dummy\",\n    \"spark.sql.catalog.demo.warehouse\": \"my-warehouse\",\n}\nspark_conf = pyspark.SparkConf()\nfor k, v in configuration.items():\n    spark_conf = spark_conf.set(k, v)\n\nspark = pyspark.sql.SparkSession.builder.config(conf=spark_conf).getOrCreate()\n\nspark.sql(\"USE demo\")\n\nspark.sql(\"CREATE NAMESPACE IF NOT EXISTS my_namespace\")\nprint(f\"\\n\\nCurrently the following namespace exist:\")\nprint(spark.sql(\"SHOW NAMESPACES\").toPandas())\nprint(\"\\n\\n\")\n\nsdf = spark.createDataFrame(\n    pd.DataFrame(\n        [[1, 1.2, \"foo\"], [2, 2.2, \"bar\"]], columns=[\"my_ints\", \"my_floats\", \"strings\"]\n    )\n)\n\nspark.sql(\"DROP TABLE IF EXISTS demo.my_namespace.my_table\")\nspark.sql(\n    \"CREATE TABLE demo.my_namespace.my_table (my_ints INT, my_floats DOUBLE, strings STRING) USING iceberg\"\n)\nsdf.writeTo(\"demo.my_namespace.my_table\").append()\nspark.table(\"demo.my_namespace.my_table\").show()\n</code></pre>"}, {"location": "support/", "title": "Community", "text": "<ul> <li> <p> Connect on Discord</p> <p>Connect with us on Discord to ask all your questions, stay up-to-date with the latest announcements and learn how others are using Lakekeeper.</p> </li> <li> <p> Report Issues &amp; Feature Request</p> <p>Open Feature Requests and report Issues on Github.</p> </li> <li> <p> Enterprise Support</p> <p>Get enterprise support for Lakekeeper in self-hosted or managed environments.</p> </li> </ul>"}, {"location": "about/code-of-conduct/", "title": "Code of Conduct", "text": "<p>Lakekeeper adheres to the Rust Code of Conduct. This describes the minimum behavior expected from all contributors. Instances of violations of the Code of Conduct can be reported by contacting the project team at moderation@vakamo.com.</p> <p>When you contribute code, you affirm that the contribution is your original work and that you license the work to the project under the project's open source license. Whether or not you state this explicitly, by submitting any copyrighted material via pull request, email, or other means you agree to license the material under the project's open source license and warrant that you have the legal authority to do so.</p>"}, {"location": "about/license/", "title": "License", "text": ""}, {"location": "about/license/#included-projects", "title": "Included projects", "text": "<p>Themes documentation is based on <code>MkDocs</code>.</p> <ul> <li>MkDocs - View license.</li> </ul> <p>Many thanks to the authors and contributors of <code>MkDocs</code>!</p>"}, {"location": "about/license/#apache-license", "title": "Apache License", "text": "<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright 2025 Vakamo Inc.</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"}, {"location": "about/release-notes/", "title": "Release Notes", "text": "<p>Please find following changes that affect the core Lakekeeper library crate. For more information, please also check our Github Releases.</p>"}, {"location": "about/release-notes/#changelog", "title": "Changelog", "text": ""}, {"location": "about/release-notes/#073-2025-03-04", "title": "0.7.3 (2025-03-04)", "text": ""}, {"location": "about/release-notes/#features", "title": "Features", "text": "<ul> <li>add EnumString to Catalog{resource}Action (efeb311)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.7.3 (630ee3a)</li> </ul>"}, {"location": "about/release-notes/#072-2025-02-27", "title": "0.7.2 (2025-02-27)", "text": ""}, {"location": "about/release-notes/#bug-fixes", "title": "Bug Fixes", "text": "<ul> <li>Authenticator order (OIDC before K8s), add K8s Authenticator Audiences (#864) (b894ba5)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_1", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.7.2 (b4c77ac)</li> </ul>"}, {"location": "about/release-notes/#071-2025-02-26", "title": "0.7.1 (2025-02-26)", "text": ""}, {"location": "about/release-notes/#features_1", "title": "Features", "text": "<ul> <li>Re-Export RequestMetadata under <code>api</code> (#850) (5a22149)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_1", "title": "Bug Fixes", "text": "<ul> <li>Client Credential Authentication for OpenFGA, allow to configure Scopes (#863) (720053b)</li> <li>more logging in validate warehouse (#860) (efc9eda)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_2", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.7.1 (05938cd)</li> </ul>"}, {"location": "about/release-notes/#070-2025-02-24", "title": "0.7.0 (2025-02-24)", "text": ""}, {"location": "about/release-notes/#features_2", "title": "Features", "text": "<ul> <li>Add Opt-In to S3 Variant prefixes (s3a, s3n) (#821) (b85b724)</li> <li>collect warehouse statistics (#811) (063066c)</li> <li>emit CloudEvent on undropTabulars #572 (#803) (9dd431a)</li> <li>Migrate Authentication to Limes, Support Unlimited Authenticators, Customizable Authentication (b72852d)</li> <li>tasks: add unit to poll interval config (#829) (c0edafa)</li> <li>use x-forwarded-for/host headers to generate links (#834) (89c0f8a)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_2", "title": "Bug Fixes", "text": "<ul> <li>deps: update rust crate rand to 0.9.0 (#785) (b9952de)</li> <li>HEAD Namespace missing in supported endpoints (#847) (f3e43fe)</li> <li>parsing of pg sslmode should be case-insensitive (#802) (1e3d001)</li> <li>s3: set path style access in s3 file_io (#796) (33e690f)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_3", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.7.0 (491940b)</li> </ul>"}, {"location": "about/release-notes/#062-2025-01-30", "title": "0.6.2 (2025-01-30)", "text": ""}, {"location": "about/release-notes/#features_3", "title": "Features", "text": "<ul> <li>Scope validation (#790) (65e664f)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_4", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.6.2 (0c7e181)</li> </ul>"}, {"location": "about/release-notes/#061-2025-01-27", "title": "0.6.1 (2025-01-27)", "text": ""}, {"location": "about/release-notes/#features_4", "title": "Features", "text": "<ul> <li>expose cloud-events tracing publisher on cli (#747) (798e85d)</li> <li>Register table endpoint (#775) (4b88f73)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_3", "title": "Bug Fixes", "text": "<ul> <li>clippy &amp; pin rust version (#758) (0899d4c)</li> <li>Table locations with same prefix (#780) (39eb3d2)</li> <li>test: use 0.3.0 for kube-auth test &amp; fix pyiceberg aws tests (#767) (e6b7b9c)</li> </ul>"}, {"location": "about/release-notes/#performance-improvements", "title": "Performance Improvements", "text": "<ul> <li>optimize load_table by refine SQL (#784) (2b87915)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_5", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.6.1 (a17f5c4)</li> </ul>"}, {"location": "about/release-notes/#060-2025-01-07", "title": "0.6.0 (2025-01-07)", "text": ""}, {"location": "about/release-notes/#features_5", "title": "Features", "text": "<ul> <li>Check Endpoint for single permissions (#706) (6a149a6)</li> <li>Lakekeeper Open Policy Agent Bridge with trino support (3735742)</li> <li>tests: run integration tests with iceberg versions: 1.5.2, 1.6.1, 1.7.1 (3f3b5ad)</li> <li>Update Lakekeeper UI to 0.4.0 (3735742)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_4", "title": "Bug Fixes", "text": "<ul> <li>credentials configs are never empty but are either null or an empty list (3f3b5ad)</li> <li>Default to purge drop for managed tables (#712) (676d995)</li> <li>Enable openfga integration tests (3735742)</li> <li>files of deleted tables not deleted for ADLS (#715) (d81677f)</li> <li>return proper error codes for invalid writes and reads of permission tuples (#727) (96c2d5e)</li> <li>use correct list of supported endpoints (3f3b5ad)</li> </ul>"}, {"location": "about/release-notes/#052-2024-12-17", "title": "0.5.2 (2024-12-17)", "text": ""}, {"location": "about/release-notes/#features_6", "title": "Features", "text": "<ul> <li>Support for Statistic Files (1e4fa38)</li> <li>tables: load table credentials (#675) (9fd272e)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_5", "title": "Bug Fixes", "text": "<ul> <li>Make BASE_URI trailing slash insensitive (#681) (4799ea7)</li> <li>Snapshots without schema (1e4fa38)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_6", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.5.2 (c5774b2)</li> </ul>"}, {"location": "about/release-notes/#051-2024-12-12", "title": "0.5.1 (2024-12-12)", "text": ""}, {"location": "about/release-notes/#features_7", "title": "Features", "text": "<ul> <li>openapi: document error models in openapi (#658) (2a67196)</li> <li>undrop  (#517) (658e757)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_6", "title": "Bug Fixes", "text": "<ul> <li>allow mixed-case properties (#660) (f435573)</li> <li>potential deadlock for views through uncommitted transactions (#638) (0dda8e3)</li> <li>potential deadlock in load-table (#636) (c22b0e0)</li> <li>remove unused relation from openfga schema (#659) (764ca5b)</li> <li>tokens of humans are wrongly identified as applications if \"appid\" claim is present (#647) (bc6b475)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_7", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.5.1 (f8aa87c)</li> </ul>"}, {"location": "about/release-notes/#050-2024-12-06", "title": "0.5.0 (2024-12-06)", "text": ""}, {"location": "about/release-notes/#breaking-changes", "title": "\u26a0 BREAKING CHANGES", "text": "<ul> <li>Rename S3 minio flavor to s3-compat (#630)</li> <li>Change default port from 8080 to 8181</li> <li>Default to single-tenant / single-project with NIL Project-ID</li> </ul>"}, {"location": "about/release-notes/#features_8", "title": "Features", "text": "<ul> <li>Add iceberg openapi to swagger (#431) (bb3d12f)</li> <li>Add Iceberg REST Spec to swagger (2eaa10e)</li> <li>add kafka support #271 (#340) (7973586)</li> <li>Add namespace_id filter to list deleted tabulars (#443) (cc82736)</li> <li>Add operator role (#543) (bcddb60)</li> <li>Allow configuration of additional Issuer URLs (b712cf0)</li> <li>Allow configuration of multiple Audiences (b712cf0)</li> <li>Change default port from 8080 to 8181 (b712cf0)</li> <li>Create default Project on Bootstrap (2eaa10e)</li> <li>Default to hard deletion (#507) (5d794aa)</li> <li>Default to single-tenant / single-project with NIL Project-ID (2eaa10e)</li> <li>docs (#605) (c1d2348)</li> <li>Embedded UI (#622) (332f3b8)</li> <li>Enable K8s Auth explicitly (#594) (3773141)</li> <li>Extend user search to email field (#477) (9f9f42b)</li> <li>Fine Grained Access Controls with OpenFGA (2eaa10e)</li> <li>Generated TS Client (#453) (24bfccf)</li> <li>Hierarchical Namespaces (2eaa10e)</li> <li>improve latency against aws by reusing http clients (#540) (8c384f7)</li> <li>OIDC Audience validation (#607) (052bb3f)</li> <li>Optionally return uuids for Iceberg APIs (2eaa10e)</li> <li>pagination without empty pages (#450) (c88a59d)</li> <li>Project Management APIs (2eaa10e)</li> <li>Provide inherited managed access via API (#619) (e7b0394)</li> <li>Rename S3 minio flavor to s3-compat (#630) (acb7419)</li> <li>Server Info Endpoint (2eaa10e)</li> <li>split table metadata into tables (#478) (942fa97)</li> <li>support kubernetes service-accounts (#538) (2982210)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_7", "title": "Bug Fixes", "text": "<ul> <li>aws s3 signer (#493) (b7ad8f4)</li> <li>aws: deal with closed connections via retries (#569) (bbda2c4)</li> <li>azure connection reset (#553) (5d4b041)</li> <li>Bootstrap should return HTTP Code 204 (#597) (25d1d4e)</li> <li>Delete Namespaces with children should not be possible (#482) (7ffd864)</li> <li>flaky aws tests (#545) (f4d46b2)</li> <li>Include Deletion Profile in GetWarehouseResponse (#514) (54a6420)</li> <li>List Namespaces - Top level NS list should only contain top level Namespaces (#512) (795d4f0)</li> <li>list-projects for non admins (#546) (d0066b8)</li> <li>management: deleted tabulars endpoint should not contain underscore (#556) (b15a8fe)</li> <li>only log table load failed when it actually happened (#626) (be5f58c)</li> <li>openapi: Fix Soft-Deletion expiration seconds type (#509) (322a1a0)</li> <li>pagination (#604) (0be19ed)</li> <li>permissions API Parameters (#516) (5133752)</li> <li>prepend a version count to metadata files (#524) (0d9d06f)</li> <li>recreate user (#599) (1194cb0)</li> <li>run metrics router (#628) (f6b47e5)</li> <li>set pool idle timeout to &lt;20 not keepalive timeout (#551) (2ae5b8d)</li> <li>tests: give openfga a bit of time to delete things (#557) (71daf6f)</li> <li>tests: use a shared runtime for tests that share a static reqwest client (#555) (90c6880)</li> <li>Warehouse managed-access in openapi spec (#610) (c860506)</li> <li>WarehouseAdmin renamed to DataAdmin (#515) (7ec4c01)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_8", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.5.0 (b1b2ee6)</li> </ul>"}, {"location": "about/release-notes/#043-2024-11-13", "title": "0.4.3 (2024-11-13)", "text": ""}, {"location": "about/release-notes/#bug-fixes_8", "title": "Bug Fixes", "text": "<ul> <li>aws s3 signer (#493) (dea4a57)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_9", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.4.3 (e577ab2)</li> </ul>"}, {"location": "about/release-notes/#042-2024-10-28", "title": "0.4.2 (2024-10-28)", "text": ""}, {"location": "about/release-notes/#features_9", "title": "Features", "text": "<ul> <li>enable native-tls-root-certs (af26004)</li> <li>improve azure latency by reusing http clients (af26004)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_10", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.4.2 (1d8c469)</li> </ul>"}, {"location": "about/release-notes/#041-2024-10-15", "title": "0.4.1 (2024-10-15)", "text": ""}, {"location": "about/release-notes/#bug-fixes_9", "title": "Bug Fixes", "text": "<ul> <li>bug in join for listing view representations (d2f1d7a)</li> <li>gcs integration test are now running in ci (d2f1d7a)</li> <li>increase keycloak timeout in integration tests (d2f1d7a)</li> <li>purge tests are now properly executed in ci (d2f1d7a)</li> </ul>"}, {"location": "about/release-notes/#040-2024-10-03", "title": "0.4.0 (2024-10-03)", "text": ""}, {"location": "about/release-notes/#breaking-changes_1", "title": "\u26a0 BREAKING CHANGES", "text": "<ul> <li>Rename TIP to Lakekeeper (#372)</li> </ul>"}, {"location": "about/release-notes/#features_10", "title": "Features", "text": "<ul> <li>cache: cache metadata location in signer (#334) (fa0863c)</li> <li>catalog: expiration queue configuration (#330) (fd96861)</li> <li>catalog: Soft-deletions &amp; tabular cleanup queues (#310) (1de63b3)</li> <li>list soft deletions (#302) (0a01eaf)</li> <li>make sure table locations are unique (#335) (543db50)</li> <li>New TableMetadataBuilder with: ID Reassignments, Metadata expiry, safe binding... (#387) (e5c1c77)</li> <li>Rename TIP to Lakekeeper (#372) (57df07e)</li> <li>storage: support for google cloud storage (gcs) (#361) (ebb4e27)</li> <li>tabular: soft-delete &amp; drop purge (#287) (475db44)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_10", "title": "Bug Fixes", "text": "<ul> <li>make conditional compilation of tests depend on var content (#311) (79036db)</li> <li>replace pretty debug prints with properly formatted errors (#327) (efe9fe9)</li> </ul>"}, {"location": "about/release-notes/#030-2024-08-26", "title": "0.3.0 (2024-08-26)", "text": ""}, {"location": "about/release-notes/#breaking-changes_2", "title": "\u26a0 BREAKING CHANGES", "text": "<ul> <li>dots can no longer be used in namespace names (#257)</li> </ul>"}, {"location": "about/release-notes/#features_11", "title": "Features", "text": "<ul> <li>Add support for custom Locations for Namespaces &amp; Tables (1d2ac6f)</li> <li>aws: sts credentials for s3 (#236) (dbf775b)</li> <li>compression-codec: Support setting and altering write.metadata.compression-codec (#235) (f4fb4cb)</li> <li>storage: add ability to narrow token permissions (#249) (ba9f046)</li> <li>storage: adls (#223) (fd11428)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_11", "title": "Bug Fixes", "text": "<ul> <li>dots can no longer be used in namespace names (#257) (8ac52e0)</li> <li>kv2: extend docs &amp; fix mismatch between docs and expected env values (#224) (be3e3e6)</li> </ul>"}, {"location": "about/release-notes/#021-2024-07-29", "title": "0.2.1 (2024-07-29)", "text": ""}, {"location": "about/release-notes/#features_12", "title": "Features", "text": "<ul> <li>db: Add Encryption Secret for postgres SecretStore to README &amp; warn on startup (#217) (933409d)</li> <li>secrets: Secret Backend configuration is now case insensitive (#215) (99b19ab)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_12", "title": "Bug Fixes", "text": "<ul> <li>examples: Fix <code>ICEBERG_REST__BASE_URI</code> (33f213b)</li> <li>s3signing: Add S3 remote signing \"content-md5\" for pyiceberg compatability (33f213b)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_11", "title": "Miscellaneous Chores", "text": "<ul> <li>release 0.2.1 (587ea12)</li> </ul>"}, {"location": "about/release-notes/#020-2024-07-26", "title": "0.2.0 (2024-07-26)", "text": ""}, {"location": "about/release-notes/#breaking-changes_3", "title": "\u26a0 BREAKING CHANGES", "text": "<ul> <li>Catalog base URL should not contain /catalog suffix (#208)</li> <li>views: split off tabular from table to prepare for views</li> </ul>"}, {"location": "about/release-notes/#features_13", "title": "Features", "text": "<ul> <li>health: Service health checks (#181) (3bf4d4c)</li> <li>pagination: add pagination for namespaces &amp; tables &amp; views (#186) (37b1dbd)</li> <li>prometheus: add prometheus axum metrics (#185) (d60d84a)</li> <li>secrets: add support for kv2 secret storage (#192) (a86b13c)</li> <li>server: make listenport configurable (#183) (9ffe0c2)</li> <li>views: authz interface for views &amp; view-ident resolve (#141) (c5e1f99)</li> <li>views: commit views (#146) (0f6310b)</li> <li>views: create + load view (#142) (328cf33)</li> <li>views: exists (#149) (fdb5013)</li> <li>views: list-views (5917a5e)</li> <li>views: rename views (#148) (4aaaa7d)</li> <li>views: split off tabular from table to prepare for views (f62b329)</li> </ul>"}, {"location": "about/release-notes/#bug-fixes_13", "title": "Bug Fixes", "text": "<ul> <li>Catalog base URL should not contain /catalog suffix (#208) (6aabaa9)</li> <li>db: add wait-for-db command (#196) (c1cd069)</li> <li>remove unused cfg-attributes (#203) (b6d17c4)</li> <li>tables: deny \"write.metadata\" &amp; \"write.data.path\" table properties  (#197) (4b2191e)</li> </ul>"}, {"location": "about/release-notes/#010-2024-06-17", "title": "0.1.0 (2024-06-17)", "text": ""}, {"location": "about/release-notes/#miscellaneous-chores_12", "title": "Miscellaneous Chores", "text": "<ul> <li>\ud83d\ude80 Release 0.1.0 (a5def9a)</li> </ul>"}, {"location": "about/release-notes/#010-rc3-2024-06-17", "title": "0.1.0-rc3 (2024-06-17)", "text": ""}, {"location": "about/release-notes/#miscellaneous-chores_13", "title": "Miscellaneous Chores", "text": "<ul> <li>\ud83d\ude80 Release 0.1.0-rc3 (9b0d219)</li> </ul>"}, {"location": "about/release-notes/#010-rc2-2024-06-17", "title": "0.1.0-rc2 (2024-06-17)", "text": ""}, {"location": "about/release-notes/#bug-fixes_14", "title": "Bug Fixes", "text": "<ul> <li>add view router (#116) (0745cc8)</li> </ul>"}, {"location": "about/release-notes/#miscellaneous-chores_14", "title": "Miscellaneous Chores", "text": "<ul> <li>\ud83d\ude80 Release 0.1.0-rc2 (9bc25ef)</li> </ul>"}, {"location": "about/release-notes/#010-rc1-2024-06-16", "title": "0.1.0-rc1 (2024-06-16)", "text": ""}, {"location": "about/release-notes/#miscellaneous-chores_15", "title": "Miscellaneous Chores", "text": "<ul> <li>\ud83d\ude80 Release 0.1.0-rc1 (ba6e5d5)</li> </ul>"}, {"location": "about/release-notes/#002-rc1-2024-06-16", "title": "0.0.2-rc1 (2024-06-16)", "text": ""}, {"location": "about/release-notes/#miscellaneous-chores_16", "title": "Miscellaneous Chores", "text": "<ul> <li>\ud83d\ude80 Release 0.0.2-rc1 (eb34b9c)</li> </ul>"}, {"location": "about/release-notes/#001-2024-06-15", "title": "0.0.1 (2024-06-15)", "text": ""}, {"location": "about/release-notes/#miscellaneous-chores_17", "title": "Miscellaneous Chores", "text": "<ul> <li>\ud83d\ude80 Release 0.0.1 (c52ddec)</li> </ul>"}, {"location": "docs/latest/authentication/", "title": "Authentication", "text": "<p>Authentication is crucial for securing access to Lakekeeper. By enabling authentication, you ensure that only authorized users can access and interact with your data. Lakekeeper supports authentication via any OpenID (or OAuth 2) capable identity provider as well as authentication for Kubernetes service accounts, allowing you to integrate with your existing identity providers.</p> <p>Authentication and Authorization are distinct processes in Lakekeeper. Authentication verifies the identity of users, ensuring that only authorized individuals can access the system. This is performed via an Identity Provider (IdP) such as OpenID or Kubernetes. Authorization, on the other hand, determines what authenticated users are allowed to do within the system. Lakekeeper is extendable and can connect to different authorization systems. By default, Lakekeeper uses OpenFGA to manage and evaluate permissions, providing a robust and flexible authorization model. For more details, see the Authorization guide.</p> <p>Lakekeeper does not issue API-Keys or Client-Credentials itself. Instead, it relies on external IdPs for authentication, ensuring a secure and centralized management of user identities. This approach minimizes the risk of credential leakage and simplifies the integration with existing security infrastructures.</p>"}, {"location": "docs/latest/authentication/#openid-provider", "title": "OpenID Provider", "text": "<p>Lakekeeper can be configured to integrate with all common identity providers. For best performance, tokens are validated locally against the server keys (<code>jwks_uri</code>). This requires all incoming tokens to be JWT tokens. If you require support for opaque tokens, please upvote the corresponding Github Issue.</p> <p>If <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is specified, Lakekeeper will  verify access tokens against this provider. The provider must provide the <code>.well-known/openid-configuration</code> endpoint and the openid-configuration needs to have <code>jwks_uri</code> and <code>issuer</code> defined. Optionally, if <code>LAKEKEEPER__OPENID_AUDIENCE</code> is specified, Lakekeeper validates the <code>aud</code> field of the provided token to match the specified value. We recommend to specify the audience in all deployments, so that tokens leaked for other applications in the same IdP cannot be used to access data in Lakekeeper.</p>"}, {"location": "docs/latest/authentication/#authenticating-machine-users", "title": "Authenticating Machine Users", "text": "<p>All common iceberg clients and IdPs support the OAuth2 <code>Client-Credential</code> flow. The <code>Client-Credential</code> flow requires a <code>Client-ID</code> and <code>Client-Secret</code> that is provided in a secure way to the client. In the following sections we demonstrate for selected IdPs how applications can be setup for machine users to connect.</p>"}, {"location": "docs/latest/authentication/#authenticating-humans", "title": "Authenticating Humans", "text": "<p>Human Authentication flows are interactive by nature and are typically performed directly by the IdP. This enables the use of all security options that the IdP supports, including 2FA, hardware keys, single-sign-on and more. The recommended flows for authentication are Authorization Code Flow RFC6749#section-4.1 with PKCE and Device Code Flow RFC8628.</p> <p>At the time of writing all common iceberg clients (spark, trino, starrocks, pyiceberg, ...) do not support any authorization flow that is suitable for human users natively. The iceberg community is working on introducing those flows and we started an initiative to standardize and document them as part of the iceberg docs.</p> <p>Until iceberg clients are natively ready for human flows, authentication flows have to be performed outside of iceberg clients. To make this process as easy as possible, the Lakekeeper UI offers the option to get a new token for a human user:</p> <p></p> <p>The lifetime of this token is specified in the corresponding application in your IdP. We recommend to set the lifetime to no longer than one day.</p>"}, {"location": "docs/latest/authentication/#keycloak", "title": "Keycloak", "text": "<p>We are creating two Client: The first client with a \"public\" profile for the Lakekeeper API &amp; UI and the second client for a machine client (e.g. Spark). Repeat step 2 for each machine client that is needed.</p>"}, {"location": "docs/latest/authentication/#client-1-lakekeeper", "title": "Client 1: Lakekeeper", "text": "<ol> <li>Create a new \"Client\":<ul> <li>Client Type: choose \"OpenID Connect\"</li> <li>Client ID: choose any, for this example we choose  <code>lakekeeper</code></li> <li>Name: choose any, for this example we choose  <code>Lakekeeper Catalog</code></li> <li>Client authentication: Leave \"Off\". We need a public client.</li> <li>Authentication Flows: Enable \"Standard flow\", OAuth 2.0 Device Authorization Grant\".</li> <li>Valid redirect URIs: For testing a wildcard \"*\" can be set. Otherwise the URL where the Lakekeeper UI is reachable for the user suffixed by <code>/callback</code>. E.g.: <code>http://localhost:8181/ui/callback</code>.</li> </ul> </li> <li>When the client is created, click on the \"Advanced\" tab of this client, scroll down to \"Advanced settings\" and set \"Access Token Lifespan\" to \"Expires in\" - 12 Hours.</li> <li>Create a new \"Client scope\" in the left side menu:<ul> <li>Name: choose any, for this example we choose  <code>lakekeeper</code> </li> <li>Description: <code>Client of Lakekeeper</code></li> <li>Type: Optional</li> </ul> </li> <li>When the scope is created, we need to add a new mapper. This is recommended because Lakekeeper can validate the <code>audience</code> (target service) of the token for increased security. In order to add the <code>lakekeeper</code> audience to the token every time the <code>lakekeeper</code> scope is requested, we create a new mapper. Select the \"Mappers\" tab of the previously created <code>lakekeeper</code> scope. Select \"Configure a new mapper\" -&gt; \"Audience\". <ul> <li>Name: choose any, for this example we choose  <code>Add lakekeeper Audience</code> </li> <li>Included Client Audience: Select the id of the previously created App 1. In our example this is <code>lakekeeper</code>.</li> <li>Make sure <code>Add to access token</code> and <code>Add to token introspection</code> is enabled.</li> </ul> </li> <li>Finally, we need to grant the <code>spark</code> client permission to use the <code>lakekeeper</code> scope which adds the correct audience to the issued token. Select the \"Client scopes\" tab of the <code>lakekeeper</code> client and select \"Add client scope\". Select the previously created scope, in our example this is <code>lakekeeper</code>. We recommend adding the scope as \"Default\".</li> </ol> <p>We are now ready to deploy Lakekeeper and login via the UI. Set the following environment variables / configurations: <pre><code>LAKEKEEPER__BASE_URI=http://localhost:8181 (URI where lakekeeper is reachable)\nLAKEKEEPER__OPENID_PROVIDER_URI=http://localhost:30080/realms/iceberg (URI of the keycloak realm)\nLAKEKEEPER__OPENID_AUDIENCE=lakekeeper (ID of Client 1)\nLAKEKEEPER__UI__OPENID_CLIENT_ID=\"lakekeeper\" (ID of Client 1)\n# LAKEKEEPER__UI__OPENID_SCOPE=\"lakekeeper\" (Name of the created scope, not required if scope was added as default)\n</code></pre></p>"}, {"location": "docs/latest/authentication/#client-2-machine-user", "title": "Client 2: Machine User", "text": "<p>Repeat this process for each query engine / machine user that is required:</p> <ol> <li>Create a new \"Client\":<ul> <li>Client Type: choose \"OpenID Connect\"</li> <li>Client ID: choose any, for this example we choose  <code>spark</code>.</li> <li>Name: choose any, for this example we choose  <code>Spark Client accessing Lakekeeper</code></li> <li>Client authentication: Turn \"On\". Leave \"Authorization\" turned \"Off\".</li> <li>Authentication Flows: Enable \"Service accounts roles\".</li> </ul> </li> <li>When the client is created, click on \"Credentials\", choose \"Client Authenticator\" as \"Client Id and Secret\". Copy the <code>Client Secret</code> for later use.</li> <li>Finally, we need to grant the <code>spark</code> client permission to use the <code>lakekeeper</code> scope which adds the correct audience to the issued token. Select the \"Client scopes\" tab of the <code>spark</code> client and select \"Add client scope\". Select the previously created scope, in our example this is <code>lakekeeper</code>. We recommend adding the scope as \"Optional\". By adding an optional scope the client can be re-used for other services, i.e. if Spark needs to access another catalog in the future.</li> </ol> <p>That's it! We can now use the second App Registration to sign into Lakekeeper using Spark or other query engines. A Spark configuration would look like:</p> PyIcebergPySpark <pre><code>import pyiceberg.catalog\nimport pyiceberg.catalog.rest\nimport pyiceberg.typedef\n\ncatalog = pyiceberg.catalog.rest.RestCatalog(\n    name=\"my_catalog_name\",\n    uri=\"http://localhost:8181/catalog\",\n    warehouse=\"&lt;warehouse name&gt;\",\n    credential=\"&lt;Client-ID of Client 2&gt;:&lt;Client-Secret of Client 2&gt;\",\n    scope=\"lakekeeper\", # Name of the created scope\n    **{\n        \"oauth2-server-uri\": \"http://localhost:30080/realms/&lt;keycloak realm name&gt;/protocol/openid-connect/token\"\n    },\n)\n\nprint(catalog.list_namespaces())\n</code></pre> <pre><code>import pyspark\n\nconf = {\n    \"spark.jars.packages\": \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.0,org.apache.iceberg:iceberg-azure-bundle:1.7.0\",\n    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n    \"spark.sql.catalog.lakekeeper\": \"org.apache.iceberg.spark.SparkCatalog\",\n    \"spark.sql.catalog.lakekeeper.type\": \"rest\",\n    \"spark.sql.catalog.lakekeeper.uri\": \"http://localhost:8181/catalog\",\n    \"spark.sql.catalog.lakekeeper.credential\": \"&lt;Client-ID of Client 2&gt;:&lt;Client-Secret of Client 2&gt;\",\n    \"spark.sql.catalog.lakekeeper.warehouse\": \"&lt;warehouse name&gt;\",\n    \"spark.sql.catalog.lakekeeper.scope\": \"lakekeeper\", # Name of the created scope\n    \"spark.sql.catalog.lakekeeper.oauth2-server-uri\": \"http://localhost:30080/realms/&lt;keycloak realm name&gt;/protocol/openid-connect/token\",\n}\nconfig = pyspark.SparkConf().setMaster(\"local\")\n\nfor k, v in conf.items():\n    config = config.set(k, v)\n\nspark = pyspark.sql.SparkSession.builder.config(conf=config).getOrCreate()\n\ntry:\n    spark.sql(\"USE `lakekeeper`\")\nexcept Exception as e:\n    print(e.stackTrace)\n    raise e\nspark.sql(\"CREATE NAMESPACE IF NOT EXISTS `test`\")\nspark.sql(\"CREATE OR REPLACE TABLE `test`.`test_tbl` AS SELECT 1 a\")\n</code></pre> <p>If Authorization is enabled, the client will throw an error as no permissions have been granted yet. During this initial connect to the <code>/config</code> endpoint of Lakekeeper, the user is automatically provisioned so that it should show up when searching for users in the \"Grant\" dialog and user search endpoints.</p>"}, {"location": "docs/latest/authentication/#entra-id-azure", "title": "Entra-ID (Azure)", "text": "<p>We are creating three App-Registrations: The first for Lakekeeper itself, the second for the Lakekeeper UI the third for a machine client (e.g. Spark) to access Lakekeeper. Repeat step 3 for each machine client that is needed. While App-Registrations can also be shared, the recommended setup we propose here offers more flexibility and better security.</p>"}, {"location": "docs/latest/authentication/#app-1-lakekeeper-ui-application", "title": "App 1: Lakekeeper UI Application", "text": "<ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Lakekeeper-UI</code></li> <li>Redirect URI: Add the URL where the Lakekeeper UI is reachable for the user suffixed by <code>/callback</code>. E.g.: <code>http://localhost:8181/ui/callback</code>. If asked, select type \"Single Page Application (SPA)\".</li> </ul> </li> <li>In the \"Overview\" page of the \"App Registration\" note down the <code>Application (client) ID</code>. Also note the <code>Directory (tenant) ID</code>.</li> <li>Finally we recommend to set a policy for tokens to expire in 12 hours instead of the default ~1 hour. Please follow the Microsoft Tutorial to assign a corresponding policy to the Application. (If you find a good way to do this via the UI, please let us know so that we can update this documentation page!)</li> </ol>"}, {"location": "docs/latest/authentication/#app-2-lakekeeper-application", "title": "App 2: Lakekeeper Application", "text": "<ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Lakekeeper</code></li> <li>Redirect URI: Leave empty.</li> </ul> </li> <li>When the App Registration is created, select \"Manage\" -&gt; \"Expose an API\" and on the top select \"Add\" beside <code>Application ID URI</code>.  Note down the <code>Application ID URI</code> (should be <code>api://&lt;Client ID&gt;</code>).</li> <li>Still in the \"Expose an API\" menus, select \"Add a Scope\". Fill the fields as follows:<ul> <li>Scope name: lakekeeper</li> <li>Who can consent? Admins and users</li> <li>Admin consent display name: Lakekeeper API</li> <li>Admin consent description: Access Lakekeeper API</li> <li>State: Enabled</li> </ul> </li> <li>After the <code>lakekeeper</code> scope is created, click \"Add a client application\" under the \"Authorized client applications\" headline. Select the previously created scope and paste as <code>Client ID</code> the previously noted ID from App 1.</li> <li>In the \"Overview\" page of the \"App Registration\" note down the <code>Application (client) ID</code>.</li> </ol> <p>We are now ready to deploy Lakekeeper and login via the UI. Set the following environment variables / configurations: <pre><code>LAKEKEEPER__BASE_URI=http://localhost:8181 (URI where lakekeeper is reachable)\n// Note the v2.0 at the End of the provider URI!\nLAKEKEEPER__OPENID_PROVIDER_URI=https://login.microsoftonline.com/&lt;Tenant ID&gt;/v2.0\nLAKEKEEPER__OPENID_AUDIENCE=\"api://&lt;Client ID from App 2 (lakekeeper)&gt;\"\nLAKEKEEPER__UI__OPENID_CLIENT_ID=\"&lt;Client ID from App 1 (lakekeeper-ui)&gt;\"\nLAKEKEEPER__UI__OPENID_SCOPE=\"openid profile api://&lt;Client ID from App 2&gt;/lakekeeper\"\nLAKEKEEPER__OPENID_ADDITIONAL_ISSUERS=\"https://sts.windows.net/&lt;Tenant ID&gt;/\"\n// The additional issuer URL is required as https://login.microsoftonline.com/&lt;Tenant ID&gt;/v2.0/.well-known/openid-configuration\n// shows https://login.microsoftonline.com as the issuer but actually\n// issues tokens for https://sts.windows.net/. This is a well-known\n// problem in Entra ID.\n</code></pre></p> <p>Before continuing with App 2, we recommend to create a Warehouse using any of the supported storages. Please check the Storage Documentation for more information. Without a Warehouse, we won't be able to test App 3.</p>"}, {"location": "docs/latest/authentication/#app-3-machine-user", "title": "App 3: Machine User", "text": "<p>Repeat this process for each query engine / machine user that is required:</p> <ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Spark</code></li> <li>Redirect URI: Leave empty - we are going to use the Client Credential Flow</li> </ul> </li> <li>When the App Registration is created, select \"Manage\" -&gt; \"Certificates &amp; secrets\" and create a \"New client secret\". Note down the secrets \"Value\".</li> </ol> <p>That's it! We can now use the second App Registration to sign into Lakekeeper using Spark or other query engines. A Spark configuration would look like:</p> PyIcebergPySpark <pre><code>import pyiceberg.catalog\nimport pyiceberg.catalog.rest\nimport pyiceberg.typedef\n\ncatalog = pyiceberg.catalog.rest.RestCatalog(\n    name=\"my_catalog_name\",\n    uri=\"http://localhost:8181/catalog\",\n    warehouse=\"&lt;warehouse name&gt;\",\n    credential=\"&lt;Client-ID of App 3 (spark)&gt;:&lt;Client-Secret of App 3 (spark)&gt;\",\n    scope=\"email openid api://&lt;Client-ID of App 2 (lakekeeper)&gt;/.default\",\n    **{\n        \"oauth2-server-uri\": \"https://login.microsoftonline.com/&lt;Tenant ID&gt;/oauth2/v2.0/token\"\n    },\n)\n\nprint(catalog.list_namespaces())\n</code></pre> <pre><code>import pyspark\n\nconf = {\n    \"spark.jars.packages\": \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.0,org.apache.iceberg:iceberg-azure-bundle:1.7.0\",\n    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n    \"spark.sql.catalog.azure-docs\": \"org.apache.iceberg.spark.SparkCatalog\",\n    \"spark.sql.catalog.azure-docs.type\": \"rest\",\n    \"spark.sql.catalog.azure-docs.uri\": \"http://localhost:8181/catalog\",\n    \"spark.sql.catalog.azure-docs.credential\": \"&lt;Client-ID of App 3 (spark)&gt;:&lt;Client-Secret of App 3 (spark)&gt;\",\n    \"spark.sql.catalog.azure-docs.warehouse\": \"&lt;warehouse name&gt;\",\n    \"spark.sql.catalog.azure-docs.scope\": \"email openid api://&lt;Client-ID of App 2 (lakekeeper)&gt;/.default\",\n    \"spark.sql.catalog.azure-docs.oauth2-server-uri\": \"https://login.microsoftonline.com/&lt;Tenant ID&gt;/oauth2/v2.0/token\",\n}\nconfig = pyspark.SparkConf().setMaster(\"local\")\n\nfor k, v in conf.items():\n    config = config.set(k, v)\n\nspark = pyspark.sql.SparkSession.builder.config(conf=config).getOrCreate()\n\ntry:\n    spark.sql(\"USE `azure-docs`\")\nexcept Exception as e:\n    print(e.stackTrace)\n    raise e\nspark.sql(\"CREATE NAMESPACE IF NOT EXISTS `test`\")\nspark.sql(\"CREATE OR REPLACE TABLE `test`.`test_tbl` AS SELECT 1 a\")\n</code></pre> <p>If Authorization is enabled, the client will throw an error as no permissions have been granted yet. During this initial connect to the <code>/config</code> endpoint of Lakekeeper, the user is automatically provisioned so that it should show up when searching for users in the \"Grant\" dialog and user search endpoints. While we try to extract the name of the application from its token, this might not be possible in all setups. As a fallback we use the <code>Client ID</code> as the name of the user. Once permissions have been granted, the user is able to perform actions.</p>"}, {"location": "docs/latest/authentication/#kubernetes", "title": "Kubernetes", "text": "<p>If <code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code> is set to true, Lakekeeper validates incoming tokens against the default kubernetes context of the system. Lakekeeper uses the <code>TokenReview</code> to determine the validity of a token. By default the <code>TokenReview</code> resource is protected. When deploying Lakekeeper on Kubernetes, make sure to grant the <code>system:auth-delegator</code> Cluster Role to the service account used by Lakekeeper:</p> <p><pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: allow-token-review\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:auth-delegator\nsubjects:\n- kind: ServiceAccount\n  name: &lt;lakekeeper-serviceaccount&gt;\n  namespace: &lt;lakekeeper-namespace&gt;\n</code></pre> The Lakekeeper Helm Chart creates the required binding by default.</p>"}, {"location": "docs/latest/authorization/", "title": "Authorization", "text": "<p>Authorization can only be enabled if Authentication is enabled. Please check the Authentication Docs for more information.</p> <p>Lakekeeper's default permission model uses the CNCF project OpenFGA to store and evaluate permissions. OpenFGA enables a powerful permission model with bi-directional inheritance, essential for managing modern lakehouses with hierarchical namespaces. Our model balances usability and control for administrators. In addition to OpenFGA, Lakekeeper's OPA bridge provides an additional translation layer that allows query engines such as trino to access Lakekeeper's permissions via Open Policy Agent (OPA). Please find more information in the OPA Bridge Guide.</p> <p>Please check the Authorization Configuration for details on enabling Authorization with Lakekeeper.</p>"}, {"location": "docs/latest/authorization/#grants", "title": "Grants", "text": "<p>The default permission model is focused on collaborating on data. Permissions are additive. The underlying OpenFGA model is defined in <code>schema.fga</code> on Github. The following grants are available:</p> Entity Grant server admin, operator project project_admin, security_admin, data_admin, role_creator, describe, select, create, modify warehouse ownership, pass_grants, manage_grants, describe, select, create, modify namespace ownership, pass_grants, manage_grants, describe, select, create, modify table ownership, pass_grants, manage_grants, describe, select, modify view ownership, pass_grants, manage_grants, describe, modify role assignee, ownership"}, {"location": "docs/latest/authorization/#ownership", "title": "Ownership", "text": "<p>Owners of objects have all rights on the specific object. When principals create new objects, they automatically become owners of these objects. This enables powerful self-service szenarios where users can act autonomously in a (sub-)namespace. By default, Owners of objects are also able to access grants on objects, which enables them to expand the access to their owned objects to new users. Enabling Managed Access for a Warehouse or Namespace removes the <code>grant</code> privilege from owners.</p>"}, {"location": "docs/latest/authorization/#server-admin", "title": "Server: Admin", "text": "<p>A <code>server</code>'s <code>admin</code> role is the most powerful role (apart from <code>operator</code>) on the server. In order to guarantee auditability, this role can list and administrate all Projects, but does not have access to data in projects. While the <code>admin</code> can assign himself the <code>project_admin</code> role for a project, this assignment is tracked by <code>OpenFGA</code> for audits. <code>admin</code>s can also manage all projects (but no entities within it), server settings and users.</p>"}, {"location": "docs/latest/authorization/#server-operator", "title": "Server: Operator", "text": "<p>The <code>operator</code> has unrestricted access to all objects in Lakekeeper. It is designed to be used by technical users (e.g., a Kubernetes Operator) managing the Lakekeeper deployment.</p>"}, {"location": "docs/latest/authorization/#project-security-admin", "title": "Project: Security Admin", "text": "<p>A <code>security_admin</code> in a project can manage all security-related aspects, including grants and ownership for the project and all objects within it. However, they cannot modify or access the content of any object, except for listing and browsing purposes.</p>"}, {"location": "docs/latest/authorization/#project-data-admin", "title": "Project: Data Admin", "text": "<p>A <code>data_admin</code> in a project can manage all data-related aspects, including creating, modifying, and deleting objects within the project. However, they cannot grant privileges or manage ownership.</p>"}, {"location": "docs/latest/authorization/#project-admin", "title": "Project: Admin", "text": "<p>A <code>project_admin</code> in a project has the combined responsibilities of both <code>security_admin</code> and <code>data_admin</code>. They can manage all security-related aspects, including grants and ownership, as well as all data-related aspects, including creating, modifying, and deleting objects within the project.</p>"}, {"location": "docs/latest/authorization/#project-role-creator", "title": "Project: Role Creator", "text": "<p>A <code>role_creator</code> in a project can create new roles within it. This role is essential for delegating the creation of roles without granting broader administrative privileges.</p>"}, {"location": "docs/latest/authorization/#describe", "title": "Describe", "text": "<p>The <code>describe</code> grant allows a user to view metadata and details about an object without modifying it. This includes listing objects and viewing their properties. The <code>describe</code> grant is inherited down the object hierarchy, meaning if a user has the <code>describe</code> grant on a higher-level entity, they can also describe all child entities within it. The <code>describe</code> grant is implicitly included with the <code>select</code>, <code>create</code>, and <code>modify</code> grants.</p>"}, {"location": "docs/latest/authorization/#select", "title": "Select", "text": "<p>The <code>select</code> grant allows a user to read data from an object, such as tables or views. This includes querying and retrieving data. The <code>select</code> grant is inherited down the object hierarchy, meaning if a user has the <code>select</code> grant on a higher-level entity, they can select all views and tables within it. The <code>select</code> grant implicitly includes the <code>describe</code> grant.</p>"}, {"location": "docs/latest/authorization/#create", "title": "Create", "text": "<p>The <code>create</code> grant allows a user to create new objects within an entity, such as tables, views, or namespaces. The <code>create</code> grant is inherited down the object hierarchy, meaning if a user has the <code>create</code> grant on a higher-level entity, they can also create objects within all child entities. The <code>create</code> grant implicitly includes the <code>describe</code> grant.</p>"}, {"location": "docs/latest/authorization/#modify", "title": "Modify", "text": "<p>The <code>modify</code> grant allows a user to change the content or properties of an object, such as updating data in tables or altering views. The <code>modify</code> grant is inherited down the object hierarchy, meaning if a user has the <code>modify</code> grant on a higher-level entity, they can also modify all child entities within it. The <code>modify</code> grant implicitly includes the <code>select</code> and <code>describe</code> grants.</p>"}, {"location": "docs/latest/authorization/#pass-grants", "title": "Pass Grants", "text": "<p>The <code>pass_grants</code> grant allows a user to pass their own privileges to other users. This means that if a user has certain permissions on an object, they can grant those same permissions to others. However, the <code>pass_grants</code> grant does not include the ability to pass the <code>pass_grants</code> privilege itself.</p>"}, {"location": "docs/latest/authorization/#manage-grants", "title": "Manage Grants", "text": "<p>The <code>manage_grants</code> grant allows a user to manage all grants on an object, including creating, modifying, and revoking grants. This also includes <code>manage_grants</code> and <code>pass_grants</code>.</p>"}, {"location": "docs/latest/authorization/#inheritance", "title": "Inheritance", "text": "<ul> <li>To-Down-Inheritance: Permissions in higher up entities are inherited to their children. For example if the <code>modify</code> privilege is granted on a <code>warehouse</code> for a principal, this principal is also able to <code>modify</code> any namespaces, including nesting ones, tables and views within it.</li> <li>Bottom-Up-Inheritance: Permissions on lower entities, for example tables, inherit basic navigational privileges to all higher layer principals. For example, if a user is granted the <code>select</code> privilege on table <code>ns1.ns2.table_1</code>, that user is implicitly granted limited list privileges on <code>ns1</code> and <code>ns2</code>. Only items in the direct path are presented to users. If <code>ns1.ns3</code> would exist as well, a list on <code>ns1</code> would only show <code>ns1.ns2</code>.</li> </ul>"}, {"location": "docs/latest/authorization/#managed-access", "title": "Managed Access", "text": "<p>Managed access is a feature designed to provide stricter control over access privileges within Lakekeeper. It is particularly useful for organizations that require a more restrictive access control model to ensure data security and compliance.</p> <p>In some cases, the default ownership model, which grants all privileges to the creator of an object, can be too permissive. This can lead to situations where non-admin users unintentionally share data with unauthorized users by granting privileges outside the scope defined by administrators. Managed access addresses this concern by removing the <code>grant</code> privilege from owners and centralizing the management of access privileges.</p> <p>With managed access, admin-like users can define access privileges on high-level container objects, such as warehouses or namespaces, and ensure that all child objects inherit these privileges. This approach prevents non-admin users from granting privileges that are not authorized by administrators, thereby reducing the risk of unintentional data sharing and enhancing overall security.</p> <p>Managed access combines elements of Role-Based Access Control (RBAC) and Discretionary Access Control (DAC). While RBAC allows privileges to be assigned to roles and users, DAC assigns ownership to the creator of an object. By integrating managed access, Lakekeeper provides a balanced access control model that supports both self-service analytics and data democratization while maintaining strict security controls.</p> <p>Managed access can be enabled or disabled for warehouses and namespaces using the UI or the <code>../managed-access</code> Endpoints. Managed access settings are inherited down the object hierarchy, meaning if managed access is enabled on a higher-level entity, it applies to all child entities within it.</p>"}, {"location": "docs/latest/authorization/#best-practices", "title": "Best Practices", "text": "<p>We recommend separating access to data from the ability to grant privileges. To achieve this, the <code>security_admin</code> and <code>data_admin</code> roles divide the responsibilities of the initial <code>project_admin</code>, who has the authority to perform tasks in both areas.</p>"}, {"location": "docs/latest/bootstrap/", "title": "Bootstrap / Initialize", "text": "<p>After the initial deployment, Lakekeeper needs to be bootstrapped. This can be done via the UI or the <code>/management/v1/bootstrap</code> endpoint. A typical POST request to bootstrap Lakekeeper looks like this:</p> <pre><code>curl --location 'https://&lt;lakekeeper-url&gt;/management/v1/bootstrap' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer &lt;my-bearer-token&gt;' \\\n--data '{\n    \"accept-terms-of-use\": true\n}'\n</code></pre> <p><code>&lt;my-bearer-token&gt;</code> is obtained by logging into the IdP before bootstrapping Lakekeeper. If authentication is disabled, no token is required. Lakekeeper can only be bootstrapped once.</p> <p>During bootstrapping, Lakekeeper performs the following actions:</p> <ul> <li>Grants the server's <code>admin</code> role to the user performing the POST request. The user is identified by their token. If authentication is disabled, the <code>Authorization</code> header is not required, and no <code>admin</code> is set, as permissions are disabled in this case.</li> <li>Stores the current Server ID to prevent unwanted future changes that would break permissions.</li> <li>Accepts terms of use as defined by our License.</li> </ul> <p>If the initial user is a technical user (e.g., a Kubernetes Operator) managing the Lakekeeper deployment, the <code>admin</code> role might not be sufficient as it limits access to projects until the <code>admin</code> grants themselves permission. For technical users, the <code>operator</code> role grants full access to all APIs and can be obtained by adding <code>\"is-operator\": true</code> to the JSON body of the bootstrap request.</p>"}, {"location": "docs/latest/concepts/", "title": "Concepts", "text": ""}, {"location": "docs/latest/concepts/#architecture", "title": "Architecture", "text": "<p>Lakekeeper is an implementation of the Apache Iceberg REST Catalog API.  Lakekeeper depends on the following, partially optional, external dependencies:</p> Connected systems. Green boxes are recommended for production. <ul> <li>Persistence Backend / Catalog (required): We currently support only Postgres, but plan to expand our support to more Databases in the future.</li> <li>Warehouse Storage (required): When a new Warehouse is created, storage credentials are required.</li> <li>Identity Provider (optional): Lakekeeper can authenticate incoming requests using any OIDC capable Identity Provider (IdP). Lakekeeper can also natively authenticate kubernetes service accounts.</li> <li>Authorization System (optional): For permission management, Lakekeeper uses the wonderful OpenFGA Project. OpenFGA is automatically deployed in our docker-compose and helm installations. Authorization can only be used if Lakekeeper is connected to an Identity Provider.</li> <li>Secret Store (optional): By default, Lakekeeper stores all secrets (i.e. S3 access credentials) encrypted in the Persistence Backend. To increase security, Lakekeeper can also use external systems to store secrets. Currently all Hashicorp-Vault like stores are supported.</li> <li>Event Store (optional): Lakekeeper can send Change Events to an Event Store. Currently Nats is supported, we are working on support for Apache Kafka</li> <li>Data Contract System (optional): Lakekeeper can interface with external data contract systems to prohibit breaking changes to your tables.</li> </ul> <p>To get started quickly with the latest version of Lakekeeper check our Getting Started Guide.</p>"}, {"location": "docs/latest/concepts/#entity-hierarchy", "title": "Entity Hierarchy", "text": "<p>In addition to entities defined in the Apache Iceberg specification or the REST specification (Namespaces, Tables, etc.), Lakekeeper introduces new entities for permission management and multi-tenant setups. The following entities are available in Lakekeeper:</p> <p></p> Lakekeeper Entity Hierarchy <p></p> <p>Project, Server, User and Roles are entities unknown to the Iceberg Rest Specification. Lakekeeper serves two APIs:</p> <ol> <li>The Iceberg REST API is served at endpoints prefixed with <code>/catalog</code>. External query engines connect to this API to interact with the Lakekeeper. Lakekeeper also implements the S3 remote signing API which is hosted at <code>/&lt;warehouse-id&gt;/v1/aws/s3/sign</code>.</li> <li>The Lakekeeper Management API is served at endpoints prefixed with <code>/management</code>. It is used to configure Lakekeeper and manage entities that are not part of the Iceberg REST Catalog specification, such as permissions.</li> </ol>"}, {"location": "docs/latest/concepts/#server", "title": "Server", "text": "<p>The Server is the highest entity in Lakekeeper, representing a single instance or a cluster of Lakekeeper pods sharing a common state. Each server has a unique identifier (UUID). By default, this <code>Server ID</code> is set to <code>00000000-0000-0000-0000-000000000000</code>. It can be changed by setting the <code>LAKEKEEPER__SERVER_ID</code> environment variable. We recommend to not set the <code>Server ID</code> explicitly, unless multiple Lakekeeper instances share a single Authorization system. The <code>Server ID</code> must not be changed after the initial bootstrapping or permissions might not work.</p>"}, {"location": "docs/latest/concepts/#project", "title": "Project", "text": "<p>For single-company setups, we recommend using a single Project setup, which is the default. Unless <code>LAKEKEEPER__ENABLE_DEFAULT_PROJECT</code> is explicitly set to <code>false</code>, a default project is created during bootstrapping with the nil UUID.</p>"}, {"location": "docs/latest/concepts/#warehouse", "title": "Warehouse", "text": "<p>Each Project can contain multiple Warehouses. Query engines connect to Lakekeeper by specifying a Warehouse name in the connection configuration.</p> <p>Each Warehouse is associated with a unique location on object stores. Never share locations between Warehouses to ensure no data is leaked via vended credentials. Each Warehouse stores information on how to connect to its location via a <code>storage-profile</code> and an optional <code>storage-credential</code>.</p> <p>Warehouses can be configured to use Soft-Deletes. When enabled, tables are not eagerly deleted but kept in a deleted state for a configurable amount of time. During this time, they can be restored. Please note that Warehouses and Namespaces cannot be deleted via the <code>/catalog</code> API if child objects are present. This includes soft-deleted Tables. A cascade-drop API is added in one of the next releases as part of the <code>/management</code> API.</p>"}, {"location": "docs/latest/concepts/#namespaces", "title": "Namespaces", "text": "<p>Each Warehouses can contain multiple Namespaces. Namespaces can be nested and serve as containers for Namespaces, Tables and Views. Using the <code>/catalog</code> API, a Namespace cannot be dropped unless it is empty. A cascade-drop API is added in one of the next releases as part of the <code>/management</code> API.</p>"}, {"location": "docs/latest/concepts/#tables-views", "title": "Tables &amp; Views", "text": "<p>Each Namespace can contain multiple Tables and Views. When creating new Tables and Views, we recommend to not specify the <code>location</code> explicitly. If locations are specified explicitly, the location must be a valid sub location of the <code>storage-profile</code> of the Warehouse - this is validated by Lakekeeper upon creation. Lakekeeper also ensures that there are no Tables or Views that use a parent- or sub-folder as their <code>location</code> and that the location is empty on creation. These checks are required to ensure that no data is leaked via vended-credentials.</p>"}, {"location": "docs/latest/concepts/#users", "title": "Users", "text": "<p>Lakekeeper is no Identity Provider. The identities of users are exclusively managed via an external Identity Provider to ensure compliance with basic security standards. Lakekeeper does not store any Password / Certificates / API Keys or any other secret that grants access to data for users. Instead, we only store Name, Email and type of users with the sole purpose of providing a convenient search while assigning privileges.</p> <p>Users can be provisioned to Lakekeeper by either of the following endpoints:</p> <ul> <li>Explicit user creation via the POST <code>/management/user</code> endpoint. This endpoint is called automatically by the UI upon login. Thus, users are \"searchable\" after their first login to the UI.</li> <li>Implicit on-the-fly creation when calling GET <code>/catalog/v1/config</code>. This can be used to register technical users simply by connecting to the Lakekeeper with your favorite tool (i.e. Spark). The initial connection will probably fail because privileges are missing to use this endpoint, but the user is provisioned anyway so that privileges can be assigned before re-connecting.</li> </ul>"}, {"location": "docs/latest/concepts/#roles", "title": "Roles", "text": "<p>Projects can contain multiple Roles, allowing Roles to be reused in all Warehouses within the Project. Roles can be nested arbitrarily, meaning that a role can contain other roles within it. Roles can be provisioned automatically using the <code>/management/v1/role</code> endpoint or manually created via the UI. We are looking into SCIM support to simplify role provisioning. Please consider upvoting the corresponding Github Issue if this would be of interest to you.</p>"}, {"location": "docs/latest/concepts/#dropping-tables", "title": "Dropping Tables", "text": "<p>Currently all tables stored in Lakekeeper are assumed to be managed by Lakekeeper. The concept of \"external\" tables will follow in a later release. When managed tables are dropped, Lakekeeper defaults to setting <code>purgeRequested</code> parameter of the <code>dropTable</code> endpoint to true unless explicitly set to false. Currently most query engines do not set this flag, which defaults to enabling purge. If purge is enabled for a drop, all files of the table are removed.</p>"}, {"location": "docs/latest/concepts/#soft-deletion", "title": "Soft Deletion", "text": "<p>In Lakekeeper, warehouses can enable soft deletion. If soft deletion is enabled for a warehouse, when a table or view is dropped, it is not immediately deleted from the catalog. Instead, it is marked as dropped and a job for its cleanup is scheduled. The table is then deleted after the warehouse specific expiration delay has passed. This will allow for a recovery of tables that have been dropped by accident. \"Undropping\" a table is only possible if soft-deletes are enabled for a Warehouse. The expiration delay is determined at the time of dropping the table, that means changing the delay in the warehouse settings will only affect newly dropped tables. If you want \"soft-deleted\" tables to be gone faster, undrop the tables, change the expiration delay and re-drop them. </p>"}, {"location": "docs/latest/concepts/#migration", "title": "Migration", "text": "<p>Migration is a crucial step that must be performed before starting the Lakekeeper. It initializes the persistent backend storage and, if enabled, the authorization system. </p> <p>For each Lakekeeper update, migration must be executed before the <code>serve</code> command can be called. This ensures that all necessary updates and configurations are applied to the system. It is possible to skip Lakekeeper versions during migration.</p>"}, {"location": "docs/latest/configuration/", "title": "Configuration", "text": "<p>Lakekeeper is configured via environment variables. Settings listed in this page are shared between all projects and warehouses. Previous to Lakekeeper Version <code>0.5.0</code> please prefix all environment variables with <code>ICEBERG_REST__</code> instead of <code>LAKEKEEPER__</code>.</p> <p>For most deployments, we recommend to set at least the following variables: <code>LAKEKEEPER__BASE_URI</code>, <code>LAKEKEEPER__PG_DATABASE_URL_READ</code>, <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code>, <code>LAKEKEEPER__PG_ENCRYPTION_KEY</code>.</p>"}, {"location": "docs/latest/configuration/#general", "title": "General", "text": "Variable Example Description <code>LAKEKEEPER__BASE_URI</code> <code>https://example.com:8181</code> Base URL where the catalog is externally reachable. Default: <code>https://localhost:8181</code> <code>LAKEKEEPER__ENABLE_DEFAULT_PROJECT</code> <code>true</code> If <code>true</code>, the NIL Project ID (\"00000000-0000-0000-0000-000000000000\") is used as a default if the user does not specify a project when connecting. This option is enabled by default, which we recommend for all single-project (single-tenant) setups. Default: <code>true</code>. <code>LAKEKEEPER__RESERVED_NAMESPACES</code> <code>system,examples,information_schema</code> Reserved Namespaces that cannot be created via the REST interface <code>LAKEKEEPER__METRICS_PORT</code> <code>9000</code> Port where the Prometheus metrics endpoint is reachable. Default: <code>9000</code> <code>LAKEKEEPER__LISTEN_PORT</code> <code>8181</code> Port the Lakekeeper listens on. Default: <code>8181</code> <code>LAKEKEEPER__SECRET_BACKEND</code> <code>postgres</code> The secret backend to use. If <code>kv2</code> (Hashicorp KV Version 2) is chosen, you need to provide additional parameters Default: <code>postgres</code>, one-of: [<code>postgres</code>, <code>kv2</code>] <code>LAKEKEEPER__ALLOW_ORIGIN</code> <code>*</code> A comma separated list of allowed origins for CORS."}, {"location": "docs/latest/configuration/#persistence-store", "title": "Persistence Store", "text": "<p>Currently Lakekeeper supports only Postgres as a persistence store. You may either provide connection strings using <code>PG_DATABASE_URL_READ</code> or use the <code>PG_*</code> environment variables. Connection strings take precedence:</p> Variable Example Description <code>LAKEKEEPER__PG_DATABASE_URL_READ</code> <code>postgres://postgres:password@localhost:5432/iceberg</code> Postgres Database connection string used for reading. Defaults to <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code>. <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code> <code>postgres://postgres:password@localhost:5432/iceberg</code> Postgres Database connection string used for writing. <code>LAKEKEEPER__PG_ENCRYPTION_KEY</code> <code>This is unsafe, please set a proper key</code> If <code>LAKEKEEPER__SECRET_BACKEND=postgres</code>, this key is used to encrypt secrets. It is required to change this for production deployments. <code>LAKEKEEPER__PG_READ_POOL_CONNECTIONS</code> <code>10</code> Number of connections in the read pool <code>LAKEKEEPER__PG_WRITE_POOL_CONNECTIONS</code> <code>5</code> Number of connections in the write pool <code>LAKEKEEPER__PG_HOST_R</code> <code>localhost</code> Hostname for read operations. Defaults to <code>LAKEKEEPER__PG_HOST_W</code>. <code>LAKEKEEPER__PG_HOST_W</code> <code>localhost</code> Hostname for write operations <code>LAKEKEEPER__PG_PORT</code> <code>5432</code> Port number <code>LAKEKEEPER__PG_USER</code> <code>postgres</code> Username for authentication <code>LAKEKEEPER__PG_PASSWORD</code> <code>password</code> Password for authentication <code>LAKEKEEPER__PG_DATABASE</code> <code>iceberg</code> Database name <code>LAKEKEEPER__PG_SSL_MODE</code> <code>require</code> SSL mode (disable, allow, prefer, require) <code>LAKEKEEPER__PG_SSL_ROOT_CERT</code> <code>/path/to/root/cert</code> Path to SSL root certificate <code>LAKEKEEPER__PG_ENABLE_STATEMENT_LOGGING</code> <code>true</code> Enable SQL statement logging <code>LAKEKEEPER__PG_TEST_BEFORE_ACQUIRE</code> <code>true</code> Test connections before acquiring from the pool <code>LAKEKEEPER__PG_CONNECTION_MAX_LIFETIME</code> <code>1800</code> Maximum lifetime of connections in seconds"}, {"location": "docs/latest/configuration/#vault-kv-version-2", "title": "Vault KV Version 2", "text": "<p>Configuration parameters if a Vault KV version 2 (i.e. Hashicorp Vault) compatible storage is used as a backend. Currently, we only support the <code>userpass</code> authentication method. Configuration may be passed as single values like <code>LAKEKEEPER__KV2__URL=http://vault.local</code> or as a compound value: <code>LAKEKEEPER__KV2='{url=\"http://localhost:1234\", user=\"test\", password=\"test\", secret_mount=\"secret\"}'</code></p> Variable Example Description <code>LAKEKEEPER__KV2__URL</code> <code>https://vault.local</code> URL of the KV2 backend <code>LAKEKEEPER__KV2__USER</code> <code>admin</code> Username to authenticate against the KV2 backend <code>LAKEKEEPER__KV2__PASSWORD</code> <code>password</code> Password to authenticate against the KV2 backend <code>LAKEKEEPER__KV2__SECRET_MOUNT</code> <code>kv/data/iceberg</code> Path to the secret mount in the KV2 backend"}, {"location": "docs/latest/configuration/#task-queues", "title": "Task queues", "text": "<p>Lakekeeper uses task queues internally to remove soft-deleted tabulars and purge tabular files. The following global configuration options are available:</p> Variable Example Description <code>LAKEKEEPER__QUEUE_CONFIG__MAX_RETRIES</code> 5 Number of retries before a task is considered failed  Default: 5 <code>LAKEKEEPER__QUEUE_CONFIG__MAX_AGE</code> 3600 Amount of seconds before a task is considered stale and could be picked up by another worker. Default: 3600 <code>LAKEKEEPER__QUEUE_CONFIG__POLL_INTERVAL</code> 10 Amount of seconds between polling for new tasks. Default: 10"}, {"location": "docs/latest/configuration/#nats", "title": "Nats", "text": "<p>Lakekeeper can publish change events to Nats (Kafka is coming soon). The following configuration options are available:</p> Variable Example Description <code>LAKEKEEPER__NATS_ADDRESS</code> <code>nats://localhost:4222</code> The URL of the NATS server to connect to <code>LAKEKEEPER__NATS_TOPIC</code> <code>iceberg</code> The subject to publish events to <code>LAKEKEEPER__NATS_USER</code> <code>test-user</code> User to authenticate against nats, needs <code>LAKEKEEPER__NATS_PASSWORD</code> <code>LAKEKEEPER__NATS_PASSWORD</code> <code>test-password</code> Password to authenticate against nats, needs <code>LAKEKEEPER__NATS_USER</code> <code>LAKEKEEPER__NATS_CREDS_FILE</code> <code>/path/to/file.creds</code> Path to a file containing nats credentials <code>LAKEKEEPER__NATS_TOKEN</code> <code>xyz</code> Nats token to use for authentication"}, {"location": "docs/latest/configuration/#authentication", "title": "Authentication", "text": "<p>To prohibit unwanted access to data, we recommend to enable Authentication.</p> <p>Authentication is enabled if:</p> <ul> <li><code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is set OR</li> <li><code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code> is set to true</li> </ul> <p>External OpenID and Kubernetes Authentication can also be enabled together. If <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is specified, Lakekeeper will  verify access tokens against this provider. The provider must provide the <code>.well-known/openid-configuration</code> endpoint and the openid-configuration needs to have <code>jwks_uri</code> and <code>issuer</code> defined. </p> <p>Typical values for <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> are:</p> <ul> <li>Keycloak: <code>https://keycloak.local/realms/{your-realm}</code></li> <li>Entra-ID: <code>https://login.microsoftonline.com/{your-tenant-id-here}/v2.0/</code></li> </ul> <p>Please check the Authentication Guide for more details.</p> Variable Example Description <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> <code>https://keycloak.local/realms/{your-realm}</code> OpenID Provider URL. <code>LAKEKEEPER__OPENID_AUDIENCE</code> <code>the-client-id-of-my-app</code> If set, the <code>aud</code> of the provided token must match the value provided. Multiple allowed audiences can be provided as a comma separated list. <code>LAKEKEEPER__OPENID_ADDITIONAL_ISSUERS</code> <code>https://sts.windows.net/&lt;Tenant&gt;/</code> A comma separated list of additional issuers to trust. The issuer defined in the <code>issuer</code> field of the <code>.well-known/openid-configuration</code> is always trusted. <code>LAKEKEEPER__OPENID_ADDITIONAL_ISSUERS</code> has no effect if <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is not set. <code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code> true If true, kubernetes service accounts can authenticate to Lakekeeper. This option is compatible with <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> - multiple IdPs (OIDC and Kubernetes) can be enabled simultaneously."}, {"location": "docs/latest/configuration/#authorization", "title": "Authorization", "text": "<p>Authorization is only effective if Authentication is enabled. Authorization must not be enabled after Lakekeeper has been bootstrapped! Please create a new Lakekeeper instance, bootstrap it with authorization enabled, and migrate your tables.</p> Variable Example Description <code>LAKEKEEPER__AUTHZ_BACKEND</code> <code>allowall</code> The authorization backend to use. If <code>openfga</code> is chosen, you need to provide additional parameters. The <code>allowall</code> backend disables authorization - authenticated users can access all endpoints. Default: <code>allowall</code>, one-of: [<code>openfga</code>, <code>allowall</code>] <code>LAKEKEEPER__OPENFGA__ENDPOINT</code> <code>http://localhost:35081</code> OpenFGA Endpoint (gRPC). <code>LAKEKEEPER__OPENFGA__STORE_NAME</code> <code>lakekeeper</code> The OpenFGA Store to use. Default: <code>lakekeeper</code> <code>LAKEKEEPER__OPENFGA__API_KEY</code> <code>my-api-key</code> The API Key used for Pre-shared key authentication to OpenFGA. If <code>LAKEKEEPER__OPENFGA__CLIENT_ID</code> is set, the API Key is ignored. If neither API Key nor Client ID is specified, no authentication is used. <code>LAKEKEEPER__OPENFGA__CLIENT_ID</code> <code>12345</code> The Client ID to use for Authenticating if OpenFGA is secured via OIDC. <code>LAKEKEEPER__OPENFGA__CLIENT_SECRET</code> <code>abcd</code> Client Secret for the Client ID. <code>LAKEKEEPER__OPENFGA__TOKEN_ENDPOINT</code> <code>https://keycloak.example.com/realms/master/protocol/openid-connect/token</code> Token Endpoint to use when exchanging client credentials for an access token for OpenFGA. Required if Client ID is set"}, {"location": "docs/latest/configuration/#ui", "title": "UI", "text": "<p>When using the built-in UI which is hosted as part of the Lakekeeper binary, most values are pre-set with the corresponding values of Lakekeeper itself. Customization is typically required if Authentication is enabled. Please check the Authentication guide for more information.</p> Variable Example Description <code>LAKEKEEPER__UI__OPENID_PROVIDER_URI</code> <code>https://keycloak.local/realms/{your-realm}</code> OpenID provider URI used for login in the UI. Defaults to <code>LAKEKEEPER__OPENID_PROVIDER_URI</code>. Set this only if the IdP is reachable under a different URI from the users browser and lakekeeper. <code>LAKEKEEPER__UI__OPENID_CLIENT_ID</code> <code>lakekeeper-ui</code> Client ID to use for the Authorization Code Flow of the UI. Required if Authentication is enabled. Defaults to <code>lakekeeper</code> <code>LAKEKEEPER__UI__OPENID_REDIRECT_PATH</code> <code>/callback</code> Path where the UI receives the callback including the tokens from the users browser. Defaults to: <code>/callback</code> <code>LAKEKEEPER__UI__OPENID_SCOPE</code> <code>openid email</code> Scopes to request from the IdP. Defaults to <code>openid profile email</code>. <code>LAKEKEEPER__UI__OPENID_RESOURCE</code> <code>lakekeeper-api</code> Resources to request from the IdP. If not specified, the <code>resource</code> field is omitted (default). <code>LAKEKEEPER__UI__OPENID_POST_LOGOUT_REDIRECT_PATH</code> <code>/logout</code> Path the UI calls when users are logged out from the IdP. Defaults to <code>/logout</code>"}, {"location": "docs/latest/configuration/#ssl-dependencies", "title": "SSL Dependencies", "text": "<p>You may be running Lakekeeper in your own environment which uses self-signed certificates for e.g. Minio. Lakekeeper is built with reqwest's <code>rustls-tls-native-roots</code> feature activated, this means <code>SSL_CERT_FILE</code> and <code>SSL_CERT_DIR</code> environment variables are respected. If both are not set, the system's default CA store is used. If you want to use a custom CA store, set <code>SSL_CERT_FILE</code> to the path of the CA file or <code>SSL_CERT_DIR</code> to the path of the CA directory. The certificate used by the server cannot be a CA. It needs to be an end entity certificate, else you may run into <code>CaUsedAsEndEntity</code> errors.</p>"}, {"location": "docs/latest/customize/", "title": "Customize", "text": "<p>As Customizability is one of the core features we are missing in other IRC implementations, we try to do things differently. The core implementation of this crate is based on four modules that back the <code>axum</code> service router:</p> <ul> <li><code>Catalog</code> is the interface to the DB backend where Warehouses, Namespaces, Tables and other entities are managed.</li> <li><code>SecretStore</code> is the interface to a secure storage for secrets.</li> <li><code>Authorizer</code> is the interface to the permission system used by Lakekeeper. It may expose its own APIs.</li> <li><code>EventPublisher</code> is the interface to message queues to send change events to.</li> <li><code>ContractValidator</code> allows an external system to prohibit changes to tables if, for example, data contracts are violated</li> <li><code>TaskQueue</code> is the interface to the task store, used to schedule tasks like soft-deletes</li> </ul> <p>All components come pre-implemented, however we encourage you to write custom implementations, for example to seamlessly grant access to tables via your companies Data Governance solution, or publish events to your very important messaging service.</p>"}, {"location": "docs/latest/developer-guide/", "title": "Developer Guide", "text": "<p>All commits to main should go through a PR. CI checks should pass before merging the PR. Before merge commits are squashed. PR titles should follow Conventional Commits.</p>"}, {"location": "docs/latest/developer-guide/#foundation-cla", "title": "Foundation &amp; CLA", "text": "<p>We hate red tape. Currently all committers need to sign the CLA in github. To ensure the future of Lakekeeper, we want to donate the project to a foundation. We are not sure yet if this is going to be Apache, Linux, a Lakekeeper foundation or something else. Currently we prefer to spent our time on adding cool new features to Lakekeeper, but we will revisit this topic during 2026.</p>"}, {"location": "docs/latest/developer-guide/#quickstart", "title": "Quickstart", "text": "<pre><code># start postgres\ndocker run -d --name postgres-15 -p 5432:5432 -e POSTGRES_PASSWORD=postgres postgres:15\n# set envs\necho 'export DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres' &gt; .env\necho 'export ICEBERG_REST__PG_ENCRYPTION_KEY=\"abc\"' &gt;&gt; .env\necho 'export ICEBERG_REST__PG_DATABASE_URL_READ=\"postgresql://postgres:postgres@localhost/postgres\"' &gt;&gt; .env\necho 'export ICEBERG_REST__PG_DATABASE_URL_WRITE=\"postgresql://postgres:postgres@localhost/postgres\"' &gt;&gt; .env\nsource .env\n\n# migrate db\ncd crates/iceberg-catalog\nsqlx database create &amp;&amp; sqlx migrate run\ncd ../..\n\n# run tests\ncargo test --all-features --all-targets\n\n# run clippy\ncargo clippy --all-features --all-targets\n</code></pre> <p>This quickstart does not run tests against cloud-storage providers or KV2. For that, please refer to the sections below.</p>"}, {"location": "docs/latest/developer-guide/#developing-with-docker-compose", "title": "Developing with docker compose", "text": "<p>The following shell snippet will start a full development environment including the catalog plus its dependencies and a jupyter server with spark. The iceberg-catalog and its migrations will be built from source. This can be useful for development and testing.</p> <pre><code>$ cd examples\n$ docker-compose -f docker-compose.yaml -f docker-compose-latest.yaml up -d --build\n</code></pre> <p>You may then head to <code>localhost:8888</code> and try out one of the notebooks.</p>"}, {"location": "docs/latest/developer-guide/#working-with-sqlx", "title": "Working with SQLx", "text": "<p>This crate uses sqlx. For development and compilation a Postgres Database is required. You can use Docker to launch one.:</p> <p><pre><code>docker run -d --name postgres-15 -p 5432:5432 -e POSTGRES_PASSWORD=postgres postgres:15\n</code></pre> The <code>crates/iceberg-catalog</code> folder contains a <code>.env.sample</code> File. Copy this file to <code>.env</code> and add your database credentials if they differ.</p> <p>Run:</p> <pre><code>sqlx database create\nsqlx migrate run\n</code></pre>"}, {"location": "docs/latest/developer-guide/#kv2-vault", "title": "KV2 / Vault", "text": "<p>This catalog supports KV2 as backend for secrets. Tests for KV2 are disabled by default. To enable them, you need to run the following commands:</p> <pre><code>docker run -d -p 8200:8200 --cap-add=IPC_LOCK -e 'VAULT_DEV_ROOT_TOKEN_ID=myroot' -e 'VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200' hashicorp/vault\n\n# append some more env vars to the .env file, it should already have PG related entries defined above.\n\n# this will enable the KV2 tests\necho 'export TEST_KV2=1' &gt;&gt; .env\n# the values below configure KV2\necho 'export ICEBERG_REST__KV2__URL=\"http://localhost:8200\"' &gt;&gt; .env\necho 'export ICEBERG_REST__KV2__USER=\"test\"' &gt;&gt; .env\necho 'export ICEBERG_REST__KV2__PASSWORD=\"test\"' &gt;&gt; .env\necho 'export ICEBERG_REST__KV2__SECRET_MOUNT=\"secret\"' &gt;&gt; .env\n\nsource .env\n# setup vault\n./tests/vault-setup.sh http://localhost:8200\n\ncargo test --all-features --all-targets\n</code></pre>"}, {"location": "docs/latest/developer-guide/#test-cloud-storage-profiles", "title": "Test cloud storage profiles", "text": "<p>Currently, we're not aware of a good way of testing cloud storage integration against local deployments. That means, in order to test against AWS S3, GCS and ADLS Gen2, you need to set the following environment variables. For more information take a look at the Storage Guide. A sample <code>.env</code> could look like this:</p> <pre><code># TEST_AZURE=&lt;some-value&gt; controls a proc macro which either includes or excludes the azure tests\n# if you compiled without TEST_AZURE, you'll have to change a file or do a cargo clean before rerunning tests. The same applies for the TEST_AWS and TEST_MINIO env vars.\nexport TEST_AZURE=1\nexport AZURE_TENANT_ID=&lt;your tenant id&gt;\nexport AZURE_CLIENT_ID=&lt;your entra id app registration client id&gt;\nexport AZURE_CLIENT_SECRET=&lt;your entra id app registration client secret&gt;\nexport AZURE_STORAGE_ACCOUNT_NAME=&lt;your azure storage account name&gt;\nexport AZURE_STORAGE_FILESYSTEM=&lt;your azure adls filesystem name&gt;\n\nexport TEST_AWS=1\nexport AWS_S3_BUCKET=&lt;your aws s3 bucket&gt;\nexport AWS_S3_REGION=&lt;your aws s3 region&gt;\n# replace with actual values\nexport AWS_S3_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE\nexport AWS_S3_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nexport AWS_S3_STS_ROLE_ARN=arn:aws:iam::123456789012:role/role-name\n\n# the values below should work with the default minio in our docker-compose\nexport TEST_MINIO=1\nexport LAKEKEEPER_TEST__S3_BUCKET=tests\nexport LAKEKEEPER_TEST__S3_REGION=local\nexport LAKEKEEPER_TEST__S3_ACCESS_KEY=minio-root-user\nexport LAKEKEEPER_TEST__S3_SECRET_KEY=minio-root-password\nexport LAKEKEEPER_TEST__S3_ENDPOINT=http://localhost:9000\n</code></pre> <p>You may then run a test via:</p> <pre><code>source .example.env-from-above\ncargo test service::storage::s3::test::aws::test_can_validate\n</code></pre>"}, {"location": "docs/latest/developer-guide/#running-integration-test", "title": "Running integration test", "text": "<p>Please check the Integration Test Docs.</p>"}, {"location": "docs/latest/developer-guide/#extending-authz", "title": "Extending Authz", "text": "<p>When adding a new endpoint, you may need to extend the authorization model. Please check the Authorization Docs for more information. For openfga, you'll have to perform the following steps:</p> <ol> <li>extend the respective enum in <code>crate::service::authz</code> by adding the new action, e.g. <code>crate::service::authz::CatalogViewAction::CanUndrop</code></li> <li>add the relation to <code>crate::service::authz::implementations::openfga::relations</code>, e.g. add <code>ViewRelation::CanUndrop</code></li> <li>add the mapping from the <code>implementations</code> type to the <code>service</code> type in <code>openfga::relations</code>, e.g. <code>CatalogViewAction::CanUndrop =&gt; ViewRelation::CanUndrop</code></li> <li>create a new authz schema version by copying the latest existing one, e.g. <code>authz/openfga/v1/</code> to <code>authz/openfga/v2/</code></li> <li>apply your changes, e.g. add <code>define can_undrop: modify</code> to the <code>view</code> type in <code>authz/openfga/v2/schema.fga</code></li> <li>create a diff between the old and new schema via <code>diff -u authz/openfga/v1/schema.fga authz/openfga/v2/schema.fga &gt; authz/openfga/v2/changed.diff</code> to help your reviewers</li> <li>regenerate <code>schema.json</code> via <code>./fga model transform --file authz/openfga/v2/schema.fga &gt; authz/openfga/v2/schema.json</code> (download the <code>fga</code> binary from the OpenFGA repo)</li> <li>Head to <code>crate::service::authz::implementations::openfga::models.rs</code>, extend <code>CollaborationModels</code> with a field for your version, e.g., <code>v2</code> and then add your new model version on top of the file, like: <pre><code>const V2_MODEL: &amp;str = include_str!(\"../../../../../../../authz/openfga/v2/schema.json\");\n\nstatic MODEL: LazyLock&lt;CollaborationModels&gt; = LazyLock::new(|| CollaborationModels {\n    v1: serde_json::from_str(V1_MODEL).expect(\"Failed to parse OpenFGA model V1 as JSON\"),\n    // this is your added model below\n    v2: serde_json::from_str(V2_MODEL).expect(\"Failed to parse OpenFGA model V2 as JSON\"),\n});\n</code></pre></li> <li>set your model as the active model like: <code>const ACTIVE_MODEL: ModelVersion = ModelVersion::V2;</code></li> <li>implement the migration in <code>crate::service::authz::implementations::openfga::migrations::migrate</code> like: <pre><code>match model_version {\n    ModelVersion::V1 =&gt; {\n    // no migration to be done, we start at v1\n    }\n    ModelVersion::V2 =&gt; v2::migrate(client, &amp;store).await,\n}\n</code></pre></li> </ol>"}, {"location": "docs/latest/opa/", "title": "Open Policy Agent (OPA)", "text": "<p>Lakekeeper's Open Policy Agent bridge enables compute engines that support fine-grained access control via Open Policy Agent (OPA) as authorization engine to respect privileges in Lakekeeper. We have also prepared a self-contained Docker Compose Example to get started quickly.</p> <p>Let's imagine we have a trusted multi-user query engine such as trino, in addition to single-user query engines like pyiceberg or daft in Jupyter Notebooks. Managing permissions in trino independently of the other tools is not an option, as we do not want to duplicate permissions across query engines. Our multi-user query engine has two options:</p> <ol> <li>Catalog enforces permissions: The engine contacts the Catalog on behalf of the user. To achieve this, the engine must be able to impersonate the user for the catalog application. In OAuth2 settings, this can be accomplished through downscoping tokens or other forms of Token Exchange.</li> <li>Compute enforces permissions: After contacting the catalog with a god-like \"I can do everything!\" user (e.g. <code>project_admin</code>), the query engine then contacts the permission system, retrieves, and enforces those permissions. Note that this requires the engine to run in a trusted environment, as whoever has root access to the engine also has access to the god-like credential.</li> </ol> <p>The Lakekeeper OPA Bridge enables solution 2, by exposing all permissions in Lakekeeper via OPA. The Bridge itself is a collection of OPA files in the <code>authz/opa-bridge</code> folder of the Lakekeeper GitHub repository.</p> <p>The bridge also comes with a translation layer for trino to translate trino to Lakekeeper permissions and thus serve trinos OPA queries. Currently trino is the only iceberg query engine we are aware of that is flexible enough to honor external permissions via OPA. Please let us know if you are aware of other engines, so that we can add support.</p>"}, {"location": "docs/latest/opa/#configuration", "title": "Configuration", "text": "<p>Lakekeeper's OPA bridge needs to access the permissions API of Lakekeeper. As such, we need a technical user for OPA (Client ID, Client Secret) that OPA can use to authenticate to Lakekeeper. Please check the Authentication guide for more information on how to create technical users. We recommend to use the same user for creating the catalog in trino to ensure same access. In most scenarios, this user should have the <code>project_admin</code> role.</p> <p>The plugin can be customized by either editing the <code>configuration.rego</code> file or by setting environment variables. By editing the <code>configuration.rego</code> files you can also easily connect multiple lakekeeper instance to the same trino instance. Please find all available configuration options explained in the file.</p> <p>If configuration is done via environment variables, the following settings are available:</p> Variable Example Description <code>LAKEKEEPER_URL</code> <code>https://lakekeeper.example.com</code> URL where lakekeeper is externally reachable. Default: <code>https://localhost:8181</code> <code>LAKEKEEPER_TOKEN_ENDPOINT</code> <code>http://keycloak:8080/realms/iceberg/protocol/openid-connect/token</code> Token endpoint of the IdP used to secure Lakekeeper. This endpoint is used to exchange OPAs client credentials for an access token. <code>LAKEKEEPER_CLIENT_ID</code> <code>trino</code> Client ID used by OPA to access Lakekeeper's permissions API. <code>LAKEKEEPER_CLIENT_SECRET</code> <code>abcd</code> Client Secret for the Client ID. <code>LAKEKEEPER_SCOPE</code> <code>lakekeeper</code> Scopes to request from the IdP. Defaults to <code>lakekeeper</code>. Please check the Authentication Guide for setup. <p>All above mentioned configuration options refer to a specific Lakekeeper instance. What is missing is a mapping of trino catalogs to Lakekeeper warehouses. By default we support 4 catalogs in trino, but more can easily be added in the <code>configuration.rego</code>.</p> Variable Example Description <code>TRINO_DEV_CATALOG_NAME</code> <code>dev</code> Name of the development catalog in trino. Default: <code>dev</code> <code>LAKEKEEPER_DEV_WAREHOUSE</code> <code>development</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_DEV_CATALOG_NAME</code> catalog in trino. Default: <code>development</code> <code>TRINO_PROD_CATALOG_NAME</code> <code>prod</code> Name of the development catalog in trino. Default: <code>prod</code> <code>LAKEKEEPER_PROD_WAREHOUSE</code> <code>production</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_PROD_CATALOG_NAME</code> catalog in trino. Default: <code>production</code> <code>TRINO_DEMO_CATALOG_NAME</code> <code>demo</code> Name of the development catalog in trino. Default: <code>prod</code> <code>LAKEKEEPER_DEMO_WAREHOUSE</code> <code>demo</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_DEMO_CATALOG_NAME</code> catalog in trino. Default: <code>demo</code> <code>TRINO_LAKEKEEPER_CATALOG_NAME</code> <code>lakekeeper</code> Name of the development catalog in trino. Default: <code>lakekeeper</code> <code>LAKEKEEPER_LAKEKEEPER_WAREHOUSE</code> <code>lakekeeper</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_LAKEKEEPER_CATALOG_NAME</code> catalog in trino. Default: <code>production</code> <p>When OPA is running and configured, set the following configurations for trino in <code>access-control.properties</code>: <pre><code>access-control.name=opa\nopa.policy.uri=http://&lt;URL where OPA is reachable&gt;/v1/data/trino/allow\nopa.log-requests=true\nopa.log-responses=true\nopa.policy.batched-uri=http://&lt;URL where OPA is reachable&gt;/v1/data/trino/batch\n</code></pre></p> <p>A full self-contained example is available on GitHub.</p>"}, {"location": "docs/latest/production/", "title": "Production Checklist", "text": "<p>Lakekeeper is the heart of your data platform and needs to integrate deeply with your existing infrastructure such as IdPs. The easiest way to get Lakekeeper to production is our enterprise support. Please find more information on our commercial offerings at lakekeeper.io</p> <p>Please find following some general recommendations for productive setups:</p> <ul> <li>Use an external high-available database as a catalog backend. We recommend using a managed service in your preferred Cloud or host a high available cluster on Kubernetes yourself using your preferred operator. We are using the amazing CloudNativePG internally. Make sure the Database is backed-up regularly.</li> <li>Ensure sure both <code>LAKEKEEPER__PG_DATABASE_URL_READ</code> and <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code> are set for ideal load distribution. Most postgres deployments specify separate URLs for reading and writing to channel writes to the master while distributing reads across replicas.</li> <li>For high-available setups, ensure that multiple Lakekeeper instances are running on different nodes. We recommend our helm chart for production deployments.</li> <li>Ensure that Authentication is enabled, typically by setting <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> and / or <code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code>. Check our Authentication Guide for more information.</li> <li>If <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is set, we recommend to set <code>LAKEKEEPER__OPENID_AUDIENCE</code> as well.</li> <li>If Authorization is desired, follow our Authorization Guide. Ensure that OpenFGA is hosted in close proximity to Lakekeeper - ideally on the same VM or Kubernetes node. In our Helm-Chart we use <code>PodAffinity</code> to achieve this.</li> <li>If the default Postgres secret backend is used, ensure that <code>LAKEKEEPER__PG_ENCRYPTION_KEY</code> is set to a long random string.</li> <li>Ensure that all Warehouses use distinct storage locations / prefixes and distinct credentials that only grant access to the prefix used for a Warehouse.</li> <li>Ensure that SSL / TLS is enabled. Lakekeeper does not terminate connections natively. Please use a reverse proxy like Nginx or Envoy to secure the connection to Lakekeeper. On Kubernetes, any Ingress controller can be used. For high-availability, failover should be handled by the reverse proxy. Lakekeeper exposes a <code>/health</code> endpoint that can be used to determine its current status. If you are using our helm-chart, probes are already built-in.</li> <li>If a trusted query engine, such as a centrally managed trino, uses Lakekeeper's OPA bridge, ensure that no users have root access to trino or OPA as those contain credentials to Lakekeeper with very high permissions.</li> </ul>"}, {"location": "docs/latest/storage/", "title": "Storage", "text": "<p>Storage in Lakekeeper is bound to a Warehouse. Each Warehouse stores data in a location defined by a <code>StorageProfile</code> attached to it.</p> <p>Currently, we support the following storages:</p> <ul> <li>S3 (tested with AWS &amp; Minio)</li> <li>Azure Data Lake Storage Gen 2</li> <li>Google Cloud Storage</li> </ul> <p>When creating a Warehouse or updating storage information, Lakekeeper validates the configuration.</p>"}, {"location": "docs/latest/storage/#s3", "title": "S3", "text": "<p>We support remote signing and vended-credentials with Minio &amp; AWS. Both provide a secure way to access data on S3:</p> <ul> <li>Remote Signing: The client prepares an S3 request and sends its headers to the sign endpoint of Lakekeeper. Lakekeeper checks if the request is allowed, if so, it signs the request with its own credentials, creating additional headers during the process. These additional signing headers are returned to the client, which then contacts S3 directly to perform the operation on files.</li> <li>Vended Credentials: Lakekeeper uses the \"STS\" Endpoint of S3 to generate temporary credentials which are then returned to clients.</li> </ul> <p>Remote signing works natively with all S3 storages that support the default <code>AWS Signature Version 4</code>. This includes almost all S3 solutions on the market today, including Minio, Rook Ceph and others. Vended credentials in turn depend on an additional \"STS\" Endpoint, that is not supported by all S3 implementations. We run our integration tests for vended credentials against Minio and AWS. We recommend to setup vended credentials for all supported stores, remote signing is not supported by all clients.</p>"}, {"location": "docs/latest/storage/#aws", "title": "AWS", "text": "<p>First create a new S3 bucket for the warehouse. Buckets can be re-used for multiple Warehouses as long as the <code>key-prefix</code> is different. We recommend to block all public access.</p> <p>Secondly we need to create an AWS role that can access and delegate access to the bucket. We start by creating a new Policy that allows access to data in the bucket. We call this policy <code>LakekeeperWarehouseDev</code>:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"ListBuckets\",\n            \"Action\": [\n                \"s3:ListAllMyBuckets\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Effect\": \"Allow\",\n            \"Resource\": [\n                \"arn:aws:s3:::*\"\n            ]\n        },\n        {\n            \"Sid\": \"ListBucketContent\",\n            \"Action\": [\n                \"s3:ListBucket\"\n            ],\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:s3:::lakekeeper-aws-demo\"\n        },\n        {\n            \"Sid\": \"DataAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::lakekeeper-aws-demo/*\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>Now create a new user, we call the user <code>LakekeeperWarehouseDev</code>, and attach the previously created policy. When the user is created, click on \"Security credentials\" and \"Create access key\". Note down the access key and secret key for later use.</p> <p>We are done if we only rely on remote signing. For vended credentials, we need to perform one more step. Create a new role that we call <code>LakekeeperWarehouseDevRole</code>. This role needs to be trusted by the user, which is achieved via with the following trust policy: <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"TrustLakekeeperWarehouseDev\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::&lt;aws-account-id&gt;:user/LakekeeperWarehouseDev\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n</code></pre></p> <p>Also attach the <code>LakekeeperWarehouseDev</code> policy created earlier.</p> <p>We are now ready to create the Warehouse via the UI or REST-API using the following values (make sure to replace everything in <code>&lt;&gt;</code>):</p> <pre><code>{\n    \"warehouse-name\": \"aws_docs\",\n    \"storage-credential\": {\n        \"type\": \"s3\",\n        \"aws-access-key-id\": \"&lt;Access Key of the created user&gt;\",\n        \"aws-secret-access-key\": \"&lt;Secret Key of the created user&gt;\",\n        \"credential-type\": \"access-key\"\n    },\n    \"storage-profile\": {\n        \"type\": \"s3\",\n        \"bucket\": \"&lt;name of the bucket&gt;\",\n        \"region\": \"&lt;region of the bucket&gt;\",\n        \"sts-enabled\": true,\n        \"flavor\": \"aws\",\n        \"key-prefix\": \"lakekeeper-dev-warehouse\",\n        \"sts-role-arn\": \"arn:aws:iam::&lt;aws account id&gt;:role/LakekeeperWarehouseDevRole\"\n    },\n    \"delete-profile\": {\n        \"type\": \"hard\"\n    }\n}\n</code></pre>"}, {"location": "docs/latest/storage/#s3-compatible", "title": "S3 Compatible", "text": "<p>Unlike for AWS, we do not need any special trust-setup for vended credentials / STS with most S3 compatible solutions like Minio. Instead, we just need a bucket and an access key / secret key combination that is able to read and write from it. If <code>sts-role-arn</code> is provided, it is ignored. Make sure to select <code>flavor</code> to have the value <code>s3-compat</code>! This setting should work for most self-hosted S3 solutions.</p> <p>An warehouse create call could look like this:</p> <pre><code>{\n    \"warehouse-name\": \"minio_dev\",\n    \"storage-credential\": {\n        \"type\": \"s3\",\n        \"aws-access-key-id\": \"&lt;Access Key of the created user&gt;\",\n        \"aws-secret-access-key\": \"&lt;Secret Key of the created user&gt;\",\n        \"credential-type\": \"access-key\"\n    },\n    \"storage-profile\": {\n        \"type\": \"s3\",\n        \"bucket\": \"&lt;name of the bucket&gt;\",\n        \"region\": \"local-01\",\n        \"sts-enabled\": true,\n        \"flavor\": \"s3-compat\",\n        \"key-prefix\": \"lakekeeper-dev-warehouse\",\n    },\n    \"delete-profile\": {\n        \"type\": \"hard\"\n    }\n}\n</code></pre>"}, {"location": "docs/latest/storage/#azure-data-lake-storage-gen-2", "title": "Azure Data Lake Storage Gen 2", "text": "<p>To add a Warehouse backed by ADLS, we need two Azure objects: The Storage Account itself and an App Registration which Lakekeeper can use to access it and delegate access to compute engines.</p> <p>Lets start by creating a new \"App Registration\":</p> <ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Lakekeeper Warehouse (Development)</code></li> <li>Redirect URI: Leave empty</li> </ul> </li> <li>When the App Registration is created, select \"Manage\" -&gt; \"Certificates &amp; secrets\" and create a \"New client secret\". Note down the secrets \"Value\".</li> <li>In the \"Overview\" page of the \"App Registration\" note down the <code>Application (client) ID</code> and the <code>Directory (tenant) ID</code>.</li> </ol> <p>Next, we create a new Storage Account. Make sure to select \"Enable hierarchical namespace\" in the \"Advanced\" section. For existing Storage Accounts make sure \"Hierarchical namespace: Enabled\" is shown in the \"Overview\" page. There are no specific requirements otherwise. Note down the name of the storage account. When the storage account is created, we need to grant the correct permissions to the \"App Registration\" and create the filesystem / container where the data is stored:</p> <ol> <li>Open the Storage Account and select \"Data storage\" -&gt; Containers. Add a new Container, we call it <code>warehouse-dev</code>.</li> <li>Next, select \"Access Control (IAM)\" in the left menu and \"Add role assignment\". Grant the <code>Storage Blob Data Contributor</code> and <code>Storage Blob Delegator</code> roles to the <code>Lakekeeper Warehouse (Development)</code> App Registration that we previously created.</li> </ol> <p>We are now ready to create the Warehouse via the UI or the REST API. Use the following information:</p> <ul> <li>client-id: The <code>Application (client) ID</code> of the <code>Lakekeeper Warehouse (Development)</code> App Registration.</li> <li>client-secret: The \"Value\" of the client secret that we noted down previously.</li> <li>tenant-id: The <code>Directory (tenant) ID</code> from the Applications Overview page.</li> <li>account-name: Name of the Storage Account</li> <li>filesystem: Name of the container (that Azure also calls filesystem) previously created. In our example its <code>warehouse-dev</code>.</li> </ul> <p>A POST request to <code>/management/v1/warehouse</code> would expects the following body:</p> <pre><code>{\n  \"warehouse-name\": \"azure_dev\",\n  \"delete-profile\": { \"type\": \"hard\" },\n  \"storage-credential\":\n    {\n      \"client-id\": \"...\",\n      \"client-secret\": \"...\",\n      \"credential-type\": \"client-credentials\",\n      \"tenant-id\": \"...\",\n      \"type\": \"az\",\n    },\n  \"storage-profile\":\n    {\n      \"account-name\": \"...\",\n      \"filesystem\": \"warehouse-dev\",\n      \"type\": \"adls\",\n    },\n}\n</code></pre>"}, {"location": "docs/latest/storage/#gcs", "title": "GCS", "text": "<p>For GCS, the used bucket needs to disable hierarchical namespaces and should have the storage admin role.</p> <p>A sample storage profile could look like this.</p> <pre><code>{\n  \"warehouse-name\": \"gcs_dev\",\n  \"storage-profile\": {\n    \"type\": \"gcs\",\n    \"bucket\": \"...\",\n    \"key-prefix\": \"...\"\n  },\n  \"storage-credential\": {\n    \"type\": \"gcs\",\n    \"credential-type\": \"service-account-key\",\n    \"key\": {\n      \"type\": \"service_account\",\n      \"project_id\": \"example-project-1234\",\n      \"private_key_id\": \"....\",\n      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n.....\\n-----END PRIVATE KEY-----\\n\",\n      \"client_email\": \"abc@example-project-1234.iam.gserviceaccount.com\",\n      \"client_id\": \"123456789012345678901\",\n      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/abc%example-project-1234.iam.gserviceaccount.com\",\n      \"universe_domain\": \"googleapis.com\"\n    }\n  }\n}\n</code></pre>"}, {"location": "docs/latest/docs/authentication/", "title": "Authentication", "text": "<p>Authentication is crucial for securing access to Lakekeeper. By enabling authentication, you ensure that only authorized users can access and interact with your data. Lakekeeper supports authentication via any OpenID (or OAuth 2) capable identity provider as well as authentication for Kubernetes service accounts, allowing you to integrate with your existing identity providers.</p> <p>Authentication and Authorization are distinct processes in Lakekeeper. Authentication verifies the identity of users, ensuring that only authorized individuals can access the system. This is performed via an Identity Provider (IdP) such as OpenID or Kubernetes. Authorization, on the other hand, determines what authenticated users are allowed to do within the system. Lakekeeper is extendable and can connect to different authorization systems. By default, Lakekeeper uses OpenFGA to manage and evaluate permissions, providing a robust and flexible authorization model. For more details, see the Authorization guide.</p> <p>Lakekeeper does not issue API-Keys or Client-Credentials itself. Instead, it relies on external IdPs for authentication, ensuring a secure and centralized management of user identities. This approach minimizes the risk of credential leakage and simplifies the integration with existing security infrastructures.</p>"}, {"location": "docs/latest/docs/authentication/#openid-provider", "title": "OpenID Provider", "text": "<p>Lakekeeper can be configured to integrate with all common identity providers. For best performance, tokens are validated locally against the server keys (<code>jwks_uri</code>). This requires all incoming tokens to be JWT tokens. If you require support for opaque tokens, please upvote the corresponding Github Issue.</p> <p>If <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is specified, Lakekeeper will  verify access tokens against this provider. The provider must provide the <code>.well-known/openid-configuration</code> endpoint and the openid-configuration needs to have <code>jwks_uri</code> and <code>issuer</code> defined. Optionally, if <code>LAKEKEEPER__OPENID_AUDIENCE</code> is specified, Lakekeeper validates the <code>aud</code> field of the provided token to match the specified value. We recommend to specify the audience in all deployments, so that tokens leaked for other applications in the same IdP cannot be used to access data in Lakekeeper.</p>"}, {"location": "docs/latest/docs/authentication/#authenticating-machine-users", "title": "Authenticating Machine Users", "text": "<p>All common iceberg clients and IdPs support the OAuth2 <code>Client-Credential</code> flow. The <code>Client-Credential</code> flow requires a <code>Client-ID</code> and <code>Client-Secret</code> that is provided in a secure way to the client. In the following sections we demonstrate for selected IdPs how applications can be setup for machine users to connect.</p>"}, {"location": "docs/latest/docs/authentication/#authenticating-humans", "title": "Authenticating Humans", "text": "<p>Human Authentication flows are interactive by nature and are typically performed directly by the IdP. This enables the use of all security options that the IdP supports, including 2FA, hardware keys, single-sign-on and more. The recommended flows for authentication are Authorization Code Flow RFC6749#section-4.1 with PKCE and Device Code Flow RFC8628.</p> <p>At the time of writing all common iceberg clients (spark, trino, starrocks, pyiceberg, ...) do not support any authorization flow that is suitable for human users natively. The iceberg community is working on introducing those flows and we started an initiative to standardize and document them as part of the iceberg docs.</p> <p>Until iceberg clients are natively ready for human flows, authentication flows have to be performed outside of iceberg clients. To make this process as easy as possible, the Lakekeeper UI offers the option to get a new token for a human user:</p> <p></p> <p>The lifetime of this token is specified in the corresponding application in your IdP. We recommend to set the lifetime to no longer than one day.</p>"}, {"location": "docs/latest/docs/authentication/#keycloak", "title": "Keycloak", "text": "<p>We are creating two Client: The first client with a \"public\" profile for the Lakekeeper API &amp; UI and the second client for a machine client (e.g. Spark). Repeat step 2 for each machine client that is needed.</p>"}, {"location": "docs/latest/docs/authentication/#client-1-lakekeeper", "title": "Client 1: Lakekeeper", "text": "<ol> <li>Create a new \"Client\":<ul> <li>Client Type: choose \"OpenID Connect\"</li> <li>Client ID: choose any, for this example we choose  <code>lakekeeper</code></li> <li>Name: choose any, for this example we choose  <code>Lakekeeper Catalog</code></li> <li>Client authentication: Leave \"Off\". We need a public client.</li> <li>Authentication Flows: Enable \"Standard flow\", OAuth 2.0 Device Authorization Grant\".</li> <li>Valid redirect URIs: For testing a wildcard \"*\" can be set. Otherwise the URL where the Lakekeeper UI is reachable for the user suffixed by <code>/callback</code>. E.g.: <code>http://localhost:8181/ui/callback</code>.</li> </ul> </li> <li>When the client is created, click on the \"Advanced\" tab of this client, scroll down to \"Advanced settings\" and set \"Access Token Lifespan\" to \"Expires in\" - 12 Hours.</li> <li>Create a new \"Client scope\" in the left side menu:<ul> <li>Name: choose any, for this example we choose  <code>lakekeeper</code> </li> <li>Description: <code>Client of Lakekeeper</code></li> <li>Type: Optional</li> </ul> </li> <li>When the scope is created, we need to add a new mapper. This is recommended because Lakekeeper can validate the <code>audience</code> (target service) of the token for increased security. In order to add the <code>lakekeeper</code> audience to the token every time the <code>lakekeeper</code> scope is requested, we create a new mapper. Select the \"Mappers\" tab of the previously created <code>lakekeeper</code> scope. Select \"Configure a new mapper\" -&gt; \"Audience\". <ul> <li>Name: choose any, for this example we choose  <code>Add lakekeeper Audience</code> </li> <li>Included Client Audience: Select the id of the previously created App 1. In our example this is <code>lakekeeper</code>.</li> <li>Make sure <code>Add to access token</code> and <code>Add to token introspection</code> is enabled.</li> </ul> </li> <li>Finally, we need to grant the <code>spark</code> client permission to use the <code>lakekeeper</code> scope which adds the correct audience to the issued token. Select the \"Client scopes\" tab of the <code>lakekeeper</code> client and select \"Add client scope\". Select the previously created scope, in our example this is <code>lakekeeper</code>. We recommend adding the scope as \"Default\".</li> </ol> <p>We are now ready to deploy Lakekeeper and login via the UI. Set the following environment variables / configurations: <pre><code>LAKEKEEPER__BASE_URI=http://localhost:8181 (URI where lakekeeper is reachable)\nLAKEKEEPER__OPENID_PROVIDER_URI=http://localhost:30080/realms/iceberg (URI of the keycloak realm)\nLAKEKEEPER__OPENID_AUDIENCE=lakekeeper (ID of Client 1)\nLAKEKEEPER__UI__OPENID_CLIENT_ID=\"lakekeeper\" (ID of Client 1)\n# LAKEKEEPER__UI__OPENID_SCOPE=\"lakekeeper\" (Name of the created scope, not required if scope was added as default)\n</code></pre></p>"}, {"location": "docs/latest/docs/authentication/#client-2-machine-user", "title": "Client 2: Machine User", "text": "<p>Repeat this process for each query engine / machine user that is required:</p> <ol> <li>Create a new \"Client\":<ul> <li>Client Type: choose \"OpenID Connect\"</li> <li>Client ID: choose any, for this example we choose  <code>spark</code>.</li> <li>Name: choose any, for this example we choose  <code>Spark Client accessing Lakekeeper</code></li> <li>Client authentication: Turn \"On\". Leave \"Authorization\" turned \"Off\".</li> <li>Authentication Flows: Enable \"Service accounts roles\".</li> </ul> </li> <li>When the client is created, click on \"Credentials\", choose \"Client Authenticator\" as \"Client Id and Secret\". Copy the <code>Client Secret</code> for later use.</li> <li>Finally, we need to grant the <code>spark</code> client permission to use the <code>lakekeeper</code> scope which adds the correct audience to the issued token. Select the \"Client scopes\" tab of the <code>spark</code> client and select \"Add client scope\". Select the previously created scope, in our example this is <code>lakekeeper</code>. We recommend adding the scope as \"Optional\". By adding an optional scope the client can be re-used for other services, i.e. if Spark needs to access another catalog in the future.</li> </ol> <p>That's it! We can now use the second App Registration to sign into Lakekeeper using Spark or other query engines. A Spark configuration would look like:</p> PyIcebergPySpark <pre><code>import pyiceberg.catalog\nimport pyiceberg.catalog.rest\nimport pyiceberg.typedef\n\ncatalog = pyiceberg.catalog.rest.RestCatalog(\n    name=\"my_catalog_name\",\n    uri=\"http://localhost:8181/catalog\",\n    warehouse=\"&lt;warehouse name&gt;\",\n    credential=\"&lt;Client-ID of Client 2&gt;:&lt;Client-Secret of Client 2&gt;\",\n    scope=\"lakekeeper\", # Name of the created scope\n    **{\n        \"oauth2-server-uri\": \"http://localhost:30080/realms/&lt;keycloak realm name&gt;/protocol/openid-connect/token\"\n    },\n)\n\nprint(catalog.list_namespaces())\n</code></pre> <pre><code>import pyspark\n\nconf = {\n    \"spark.jars.packages\": \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.0,org.apache.iceberg:iceberg-azure-bundle:1.7.0\",\n    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n    \"spark.sql.catalog.lakekeeper\": \"org.apache.iceberg.spark.SparkCatalog\",\n    \"spark.sql.catalog.lakekeeper.type\": \"rest\",\n    \"spark.sql.catalog.lakekeeper.uri\": \"http://localhost:8181/catalog\",\n    \"spark.sql.catalog.lakekeeper.credential\": \"&lt;Client-ID of Client 2&gt;:&lt;Client-Secret of Client 2&gt;\",\n    \"spark.sql.catalog.lakekeeper.warehouse\": \"&lt;warehouse name&gt;\",\n    \"spark.sql.catalog.lakekeeper.scope\": \"lakekeeper\", # Name of the created scope\n    \"spark.sql.catalog.lakekeeper.oauth2-server-uri\": \"http://localhost:30080/realms/&lt;keycloak realm name&gt;/protocol/openid-connect/token\",\n}\nconfig = pyspark.SparkConf().setMaster(\"local\")\n\nfor k, v in conf.items():\n    config = config.set(k, v)\n\nspark = pyspark.sql.SparkSession.builder.config(conf=config).getOrCreate()\n\ntry:\n    spark.sql(\"USE `lakekeeper`\")\nexcept Exception as e:\n    print(e.stackTrace)\n    raise e\nspark.sql(\"CREATE NAMESPACE IF NOT EXISTS `test`\")\nspark.sql(\"CREATE OR REPLACE TABLE `test`.`test_tbl` AS SELECT 1 a\")\n</code></pre> <p>If Authorization is enabled, the client will throw an error as no permissions have been granted yet. During this initial connect to the <code>/config</code> endpoint of Lakekeeper, the user is automatically provisioned so that it should show up when searching for users in the \"Grant\" dialog and user search endpoints.</p>"}, {"location": "docs/latest/docs/authentication/#entra-id-azure", "title": "Entra-ID (Azure)", "text": "<p>We are creating three App-Registrations: The first for Lakekeeper itself, the second for the Lakekeeper UI the third for a machine client (e.g. Spark) to access Lakekeeper. Repeat step 3 for each machine client that is needed. While App-Registrations can also be shared, the recommended setup we propose here offers more flexibility and better security.</p>"}, {"location": "docs/latest/docs/authentication/#app-1-lakekeeper-ui-application", "title": "App 1: Lakekeeper UI Application", "text": "<ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Lakekeeper-UI</code></li> <li>Redirect URI: Add the URL where the Lakekeeper UI is reachable for the user suffixed by <code>/callback</code>. E.g.: <code>http://localhost:8181/ui/callback</code>. If asked, select type \"Single Page Application (SPA)\".</li> </ul> </li> <li>In the \"Overview\" page of the \"App Registration\" note down the <code>Application (client) ID</code>. Also note the <code>Directory (tenant) ID</code>.</li> <li>Finally we recommend to set a policy for tokens to expire in 12 hours instead of the default ~1 hour. Please follow the Microsoft Tutorial to assign a corresponding policy to the Application. (If you find a good way to do this via the UI, please let us know so that we can update this documentation page!)</li> </ol>"}, {"location": "docs/latest/docs/authentication/#app-2-lakekeeper-application", "title": "App 2: Lakekeeper Application", "text": "<ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Lakekeeper</code></li> <li>Redirect URI: Leave empty.</li> </ul> </li> <li>When the App Registration is created, select \"Manage\" -&gt; \"Expose an API\" and on the top select \"Add\" beside <code>Application ID URI</code>.  Note down the <code>Application ID URI</code> (should be <code>api://&lt;Client ID&gt;</code>).</li> <li>Still in the \"Expose an API\" menus, select \"Add a Scope\". Fill the fields as follows:<ul> <li>Scope name: lakekeeper</li> <li>Who can consent? Admins and users</li> <li>Admin consent display name: Lakekeeper API</li> <li>Admin consent description: Access Lakekeeper API</li> <li>State: Enabled</li> </ul> </li> <li>After the <code>lakekeeper</code> scope is created, click \"Add a client application\" under the \"Authorized client applications\" headline. Select the previously created scope and paste as <code>Client ID</code> the previously noted ID from App 1.</li> <li>In the \"Overview\" page of the \"App Registration\" note down the <code>Application (client) ID</code>.</li> </ol> <p>We are now ready to deploy Lakekeeper and login via the UI. Set the following environment variables / configurations: <pre><code>LAKEKEEPER__BASE_URI=http://localhost:8181 (URI where lakekeeper is reachable)\n// Note the v2.0 at the End of the provider URI!\nLAKEKEEPER__OPENID_PROVIDER_URI=https://login.microsoftonline.com/&lt;Tenant ID&gt;/v2.0\nLAKEKEEPER__OPENID_AUDIENCE=\"api://&lt;Client ID from App 2 (lakekeeper)&gt;\"\nLAKEKEEPER__UI__OPENID_CLIENT_ID=\"&lt;Client ID from App 1 (lakekeeper-ui)&gt;\"\nLAKEKEEPER__UI__OPENID_SCOPE=\"openid profile api://&lt;Client ID from App 2&gt;/lakekeeper\"\nLAKEKEEPER__OPENID_ADDITIONAL_ISSUERS=\"https://sts.windows.net/&lt;Tenant ID&gt;/\"\n// The additional issuer URL is required as https://login.microsoftonline.com/&lt;Tenant ID&gt;/v2.0/.well-known/openid-configuration\n// shows https://login.microsoftonline.com as the issuer but actually\n// issues tokens for https://sts.windows.net/. This is a well-known\n// problem in Entra ID.\n</code></pre></p> <p>Before continuing with App 2, we recommend to create a Warehouse using any of the supported storages. Please check the Storage Documentation for more information. Without a Warehouse, we won't be able to test App 3.</p>"}, {"location": "docs/latest/docs/authentication/#app-3-machine-user", "title": "App 3: Machine User", "text": "<p>Repeat this process for each query engine / machine user that is required:</p> <ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Spark</code></li> <li>Redirect URI: Leave empty - we are going to use the Client Credential Flow</li> </ul> </li> <li>When the App Registration is created, select \"Manage\" -&gt; \"Certificates &amp; secrets\" and create a \"New client secret\". Note down the secrets \"Value\".</li> </ol> <p>That's it! We can now use the second App Registration to sign into Lakekeeper using Spark or other query engines. A Spark configuration would look like:</p> PyIcebergPySpark <pre><code>import pyiceberg.catalog\nimport pyiceberg.catalog.rest\nimport pyiceberg.typedef\n\ncatalog = pyiceberg.catalog.rest.RestCatalog(\n    name=\"my_catalog_name\",\n    uri=\"http://localhost:8181/catalog\",\n    warehouse=\"&lt;warehouse name&gt;\",\n    credential=\"&lt;Client-ID of App 3 (spark)&gt;:&lt;Client-Secret of App 3 (spark)&gt;\",\n    scope=\"email openid api://&lt;Client-ID of App 2 (lakekeeper)&gt;/.default\",\n    **{\n        \"oauth2-server-uri\": \"https://login.microsoftonline.com/&lt;Tenant ID&gt;/oauth2/v2.0/token\"\n    },\n)\n\nprint(catalog.list_namespaces())\n</code></pre> <pre><code>import pyspark\n\nconf = {\n    \"spark.jars.packages\": \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.0,org.apache.iceberg:iceberg-azure-bundle:1.7.0\",\n    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n    \"spark.sql.catalog.azure-docs\": \"org.apache.iceberg.spark.SparkCatalog\",\n    \"spark.sql.catalog.azure-docs.type\": \"rest\",\n    \"spark.sql.catalog.azure-docs.uri\": \"http://localhost:8181/catalog\",\n    \"spark.sql.catalog.azure-docs.credential\": \"&lt;Client-ID of App 3 (spark)&gt;:&lt;Client-Secret of App 3 (spark)&gt;\",\n    \"spark.sql.catalog.azure-docs.warehouse\": \"&lt;warehouse name&gt;\",\n    \"spark.sql.catalog.azure-docs.scope\": \"email openid api://&lt;Client-ID of App 2 (lakekeeper)&gt;/.default\",\n    \"spark.sql.catalog.azure-docs.oauth2-server-uri\": \"https://login.microsoftonline.com/&lt;Tenant ID&gt;/oauth2/v2.0/token\",\n}\nconfig = pyspark.SparkConf().setMaster(\"local\")\n\nfor k, v in conf.items():\n    config = config.set(k, v)\n\nspark = pyspark.sql.SparkSession.builder.config(conf=config).getOrCreate()\n\ntry:\n    spark.sql(\"USE `azure-docs`\")\nexcept Exception as e:\n    print(e.stackTrace)\n    raise e\nspark.sql(\"CREATE NAMESPACE IF NOT EXISTS `test`\")\nspark.sql(\"CREATE OR REPLACE TABLE `test`.`test_tbl` AS SELECT 1 a\")\n</code></pre> <p>If Authorization is enabled, the client will throw an error as no permissions have been granted yet. During this initial connect to the <code>/config</code> endpoint of Lakekeeper, the user is automatically provisioned so that it should show up when searching for users in the \"Grant\" dialog and user search endpoints. While we try to extract the name of the application from its token, this might not be possible in all setups. As a fallback we use the <code>Client ID</code> as the name of the user. Once permissions have been granted, the user is able to perform actions.</p>"}, {"location": "docs/latest/docs/authentication/#kubernetes", "title": "Kubernetes", "text": "<p>If <code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code> is set to true, Lakekeeper validates incoming tokens against the default kubernetes context of the system. Lakekeeper uses the <code>TokenReview</code> to determine the validity of a token. By default the <code>TokenReview</code> resource is protected. When deploying Lakekeeper on Kubernetes, make sure to grant the <code>system:auth-delegator</code> Cluster Role to the service account used by Lakekeeper:</p> <p><pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: allow-token-review\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:auth-delegator\nsubjects:\n- kind: ServiceAccount\n  name: &lt;lakekeeper-serviceaccount&gt;\n  namespace: &lt;lakekeeper-namespace&gt;\n</code></pre> The Lakekeeper Helm Chart creates the required binding by default.</p>"}, {"location": "docs/latest/docs/authorization/", "title": "Authorization", "text": "<p>Authorization can only be enabled if Authentication is enabled. Please check the Authentication Docs for more information.</p> <p>Lakekeeper's default permission model uses the CNCF project OpenFGA to store and evaluate permissions. OpenFGA enables a powerful permission model with bi-directional inheritance, essential for managing modern lakehouses with hierarchical namespaces. Our model balances usability and control for administrators. In addition to OpenFGA, Lakekeeper's OPA bridge provides an additional translation layer that allows query engines such as trino to access Lakekeeper's permissions via Open Policy Agent (OPA). Please find more information in the OPA Bridge Guide.</p> <p>Please check the Authorization Configuration for details on enabling Authorization with Lakekeeper.</p>"}, {"location": "docs/latest/docs/authorization/#grants", "title": "Grants", "text": "<p>The default permission model is focused on collaborating on data. Permissions are additive. The underlying OpenFGA model is defined in <code>schema.fga</code> on Github. The following grants are available:</p> Entity Grant server admin, operator project project_admin, security_admin, data_admin, role_creator, describe, select, create, modify warehouse ownership, pass_grants, manage_grants, describe, select, create, modify namespace ownership, pass_grants, manage_grants, describe, select, create, modify table ownership, pass_grants, manage_grants, describe, select, modify view ownership, pass_grants, manage_grants, describe, modify role assignee, ownership"}, {"location": "docs/latest/docs/authorization/#ownership", "title": "Ownership", "text": "<p>Owners of objects have all rights on the specific object. When principals create new objects, they automatically become owners of these objects. This enables powerful self-service szenarios where users can act autonomously in a (sub-)namespace. By default, Owners of objects are also able to access grants on objects, which enables them to expand the access to their owned objects to new users. Enabling Managed Access for a Warehouse or Namespace removes the <code>grant</code> privilege from owners.</p>"}, {"location": "docs/latest/docs/authorization/#server-admin", "title": "Server: Admin", "text": "<p>A <code>server</code>'s <code>admin</code> role is the most powerful role (apart from <code>operator</code>) on the server. In order to guarantee auditability, this role can list and administrate all Projects, but does not have access to data in projects. While the <code>admin</code> can assign himself the <code>project_admin</code> role for a project, this assignment is tracked by <code>OpenFGA</code> for audits. <code>admin</code>s can also manage all projects (but no entities within it), server settings and users.</p>"}, {"location": "docs/latest/docs/authorization/#server-operator", "title": "Server: Operator", "text": "<p>The <code>operator</code> has unrestricted access to all objects in Lakekeeper. It is designed to be used by technical users (e.g., a Kubernetes Operator) managing the Lakekeeper deployment.</p>"}, {"location": "docs/latest/docs/authorization/#project-security-admin", "title": "Project: Security Admin", "text": "<p>A <code>security_admin</code> in a project can manage all security-related aspects, including grants and ownership for the project and all objects within it. However, they cannot modify or access the content of any object, except for listing and browsing purposes.</p>"}, {"location": "docs/latest/docs/authorization/#project-data-admin", "title": "Project: Data Admin", "text": "<p>A <code>data_admin</code> in a project can manage all data-related aspects, including creating, modifying, and deleting objects within the project. However, they cannot grant privileges or manage ownership.</p>"}, {"location": "docs/latest/docs/authorization/#project-admin", "title": "Project: Admin", "text": "<p>A <code>project_admin</code> in a project has the combined responsibilities of both <code>security_admin</code> and <code>data_admin</code>. They can manage all security-related aspects, including grants and ownership, as well as all data-related aspects, including creating, modifying, and deleting objects within the project.</p>"}, {"location": "docs/latest/docs/authorization/#project-role-creator", "title": "Project: Role Creator", "text": "<p>A <code>role_creator</code> in a project can create new roles within it. This role is essential for delegating the creation of roles without granting broader administrative privileges.</p>"}, {"location": "docs/latest/docs/authorization/#describe", "title": "Describe", "text": "<p>The <code>describe</code> grant allows a user to view metadata and details about an object without modifying it. This includes listing objects and viewing their properties. The <code>describe</code> grant is inherited down the object hierarchy, meaning if a user has the <code>describe</code> grant on a higher-level entity, they can also describe all child entities within it. The <code>describe</code> grant is implicitly included with the <code>select</code>, <code>create</code>, and <code>modify</code> grants.</p>"}, {"location": "docs/latest/docs/authorization/#select", "title": "Select", "text": "<p>The <code>select</code> grant allows a user to read data from an object, such as tables or views. This includes querying and retrieving data. The <code>select</code> grant is inherited down the object hierarchy, meaning if a user has the <code>select</code> grant on a higher-level entity, they can select all views and tables within it. The <code>select</code> grant implicitly includes the <code>describe</code> grant.</p>"}, {"location": "docs/latest/docs/authorization/#create", "title": "Create", "text": "<p>The <code>create</code> grant allows a user to create new objects within an entity, such as tables, views, or namespaces. The <code>create</code> grant is inherited down the object hierarchy, meaning if a user has the <code>create</code> grant on a higher-level entity, they can also create objects within all child entities. The <code>create</code> grant implicitly includes the <code>describe</code> grant.</p>"}, {"location": "docs/latest/docs/authorization/#modify", "title": "Modify", "text": "<p>The <code>modify</code> grant allows a user to change the content or properties of an object, such as updating data in tables or altering views. The <code>modify</code> grant is inherited down the object hierarchy, meaning if a user has the <code>modify</code> grant on a higher-level entity, they can also modify all child entities within it. The <code>modify</code> grant implicitly includes the <code>select</code> and <code>describe</code> grants.</p>"}, {"location": "docs/latest/docs/authorization/#pass-grants", "title": "Pass Grants", "text": "<p>The <code>pass_grants</code> grant allows a user to pass their own privileges to other users. This means that if a user has certain permissions on an object, they can grant those same permissions to others. However, the <code>pass_grants</code> grant does not include the ability to pass the <code>pass_grants</code> privilege itself.</p>"}, {"location": "docs/latest/docs/authorization/#manage-grants", "title": "Manage Grants", "text": "<p>The <code>manage_grants</code> grant allows a user to manage all grants on an object, including creating, modifying, and revoking grants. This also includes <code>manage_grants</code> and <code>pass_grants</code>.</p>"}, {"location": "docs/latest/docs/authorization/#inheritance", "title": "Inheritance", "text": "<ul> <li>To-Down-Inheritance: Permissions in higher up entities are inherited to their children. For example if the <code>modify</code> privilege is granted on a <code>warehouse</code> for a principal, this principal is also able to <code>modify</code> any namespaces, including nesting ones, tables and views within it.</li> <li>Bottom-Up-Inheritance: Permissions on lower entities, for example tables, inherit basic navigational privileges to all higher layer principals. For example, if a user is granted the <code>select</code> privilege on table <code>ns1.ns2.table_1</code>, that user is implicitly granted limited list privileges on <code>ns1</code> and <code>ns2</code>. Only items in the direct path are presented to users. If <code>ns1.ns3</code> would exist as well, a list on <code>ns1</code> would only show <code>ns1.ns2</code>.</li> </ul>"}, {"location": "docs/latest/docs/authorization/#managed-access", "title": "Managed Access", "text": "<p>Managed access is a feature designed to provide stricter control over access privileges within Lakekeeper. It is particularly useful for organizations that require a more restrictive access control model to ensure data security and compliance.</p> <p>In some cases, the default ownership model, which grants all privileges to the creator of an object, can be too permissive. This can lead to situations where non-admin users unintentionally share data with unauthorized users by granting privileges outside the scope defined by administrators. Managed access addresses this concern by removing the <code>grant</code> privilege from owners and centralizing the management of access privileges.</p> <p>With managed access, admin-like users can define access privileges on high-level container objects, such as warehouses or namespaces, and ensure that all child objects inherit these privileges. This approach prevents non-admin users from granting privileges that are not authorized by administrators, thereby reducing the risk of unintentional data sharing and enhancing overall security.</p> <p>Managed access combines elements of Role-Based Access Control (RBAC) and Discretionary Access Control (DAC). While RBAC allows privileges to be assigned to roles and users, DAC assigns ownership to the creator of an object. By integrating managed access, Lakekeeper provides a balanced access control model that supports both self-service analytics and data democratization while maintaining strict security controls.</p> <p>Managed access can be enabled or disabled for warehouses and namespaces using the UI or the <code>../managed-access</code> Endpoints. Managed access settings are inherited down the object hierarchy, meaning if managed access is enabled on a higher-level entity, it applies to all child entities within it.</p>"}, {"location": "docs/latest/docs/authorization/#best-practices", "title": "Best Practices", "text": "<p>We recommend separating access to data from the ability to grant privileges. To achieve this, the <code>security_admin</code> and <code>data_admin</code> roles divide the responsibilities of the initial <code>project_admin</code>, who has the authority to perform tasks in both areas.</p>"}, {"location": "docs/latest/docs/bootstrap/", "title": "Bootstrap / Initialize", "text": "<p>After the initial deployment, Lakekeeper needs to be bootstrapped. This can be done via the UI or the <code>/management/v1/bootstrap</code> endpoint. A typical POST request to bootstrap Lakekeeper looks like this:</p> <pre><code>curl --location 'https://&lt;lakekeeper-url&gt;/management/v1/bootstrap' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer &lt;my-bearer-token&gt;' \\\n--data '{\n    \"accept-terms-of-use\": true\n}'\n</code></pre> <p><code>&lt;my-bearer-token&gt;</code> is obtained by logging into the IdP before bootstrapping Lakekeeper. If authentication is disabled, no token is required. Lakekeeper can only be bootstrapped once.</p> <p>During bootstrapping, Lakekeeper performs the following actions:</p> <ul> <li>Grants the server's <code>admin</code> role to the user performing the POST request. The user is identified by their token. If authentication is disabled, the <code>Authorization</code> header is not required, and no <code>admin</code> is set, as permissions are disabled in this case.</li> <li>Stores the current Server ID to prevent unwanted future changes that would break permissions.</li> <li>Accepts terms of use as defined by our License.</li> </ul> <p>If the initial user is a technical user (e.g., a Kubernetes Operator) managing the Lakekeeper deployment, the <code>admin</code> role might not be sufficient as it limits access to projects until the <code>admin</code> grants themselves permission. For technical users, the <code>operator</code> role grants full access to all APIs and can be obtained by adding <code>\"is-operator\": true</code> to the JSON body of the bootstrap request.</p>"}, {"location": "docs/latest/docs/concepts/", "title": "Concepts", "text": ""}, {"location": "docs/latest/docs/concepts/#architecture", "title": "Architecture", "text": "<p>Lakekeeper is an implementation of the Apache Iceberg REST Catalog API.  Lakekeeper depends on the following, partially optional, external dependencies:</p> Connected systems. Green boxes are recommended for production. <ul> <li>Persistence Backend / Catalog (required): We currently support only Postgres, but plan to expand our support to more Databases in the future.</li> <li>Warehouse Storage (required): When a new Warehouse is created, storage credentials are required.</li> <li>Identity Provider (optional): Lakekeeper can authenticate incoming requests using any OIDC capable Identity Provider (IdP). Lakekeeper can also natively authenticate kubernetes service accounts.</li> <li>Authorization System (optional): For permission management, Lakekeeper uses the wonderful OpenFGA Project. OpenFGA is automatically deployed in our docker-compose and helm installations. Authorization can only be used if Lakekeeper is connected to an Identity Provider.</li> <li>Secret Store (optional): By default, Lakekeeper stores all secrets (i.e. S3 access credentials) encrypted in the Persistence Backend. To increase security, Lakekeeper can also use external systems to store secrets. Currently all Hashicorp-Vault like stores are supported.</li> <li>Event Store (optional): Lakekeeper can send Change Events to an Event Store. Currently Nats is supported, we are working on support for Apache Kafka</li> <li>Data Contract System (optional): Lakekeeper can interface with external data contract systems to prohibit breaking changes to your tables.</li> </ul> <p>To get started quickly with the latest version of Lakekeeper check our Getting Started Guide.</p>"}, {"location": "docs/latest/docs/concepts/#entity-hierarchy", "title": "Entity Hierarchy", "text": "<p>In addition to entities defined in the Apache Iceberg specification or the REST specification (Namespaces, Tables, etc.), Lakekeeper introduces new entities for permission management and multi-tenant setups. The following entities are available in Lakekeeper:</p> <p></p> Lakekeeper Entity Hierarchy <p></p> <p>Project, Server, User and Roles are entities unknown to the Iceberg Rest Specification. Lakekeeper serves two APIs:</p> <ol> <li>The Iceberg REST API is served at endpoints prefixed with <code>/catalog</code>. External query engines connect to this API to interact with the Lakekeeper. Lakekeeper also implements the S3 remote signing API which is hosted at <code>/&lt;warehouse-id&gt;/v1/aws/s3/sign</code>.</li> <li>The Lakekeeper Management API is served at endpoints prefixed with <code>/management</code>. It is used to configure Lakekeeper and manage entities that are not part of the Iceberg REST Catalog specification, such as permissions.</li> </ol>"}, {"location": "docs/latest/docs/concepts/#server", "title": "Server", "text": "<p>The Server is the highest entity in Lakekeeper, representing a single instance or a cluster of Lakekeeper pods sharing a common state. Each server has a unique identifier (UUID). By default, this <code>Server ID</code> is set to <code>00000000-0000-0000-0000-000000000000</code>. It can be changed by setting the <code>LAKEKEEPER__SERVER_ID</code> environment variable. We recommend to not set the <code>Server ID</code> explicitly, unless multiple Lakekeeper instances share a single Authorization system. The <code>Server ID</code> must not be changed after the initial bootstrapping or permissions might not work.</p>"}, {"location": "docs/latest/docs/concepts/#project", "title": "Project", "text": "<p>For single-company setups, we recommend using a single Project setup, which is the default. Unless <code>LAKEKEEPER__ENABLE_DEFAULT_PROJECT</code> is explicitly set to <code>false</code>, a default project is created during bootstrapping with the nil UUID.</p>"}, {"location": "docs/latest/docs/concepts/#warehouse", "title": "Warehouse", "text": "<p>Each Project can contain multiple Warehouses. Query engines connect to Lakekeeper by specifying a Warehouse name in the connection configuration.</p> <p>Each Warehouse is associated with a unique location on object stores. Never share locations between Warehouses to ensure no data is leaked via vended credentials. Each Warehouse stores information on how to connect to its location via a <code>storage-profile</code> and an optional <code>storage-credential</code>.</p> <p>Warehouses can be configured to use Soft-Deletes. When enabled, tables are not eagerly deleted but kept in a deleted state for a configurable amount of time. During this time, they can be restored. Please note that Warehouses and Namespaces cannot be deleted via the <code>/catalog</code> API if child objects are present. This includes soft-deleted Tables. A cascade-drop API is added in one of the next releases as part of the <code>/management</code> API.</p>"}, {"location": "docs/latest/docs/concepts/#namespaces", "title": "Namespaces", "text": "<p>Each Warehouses can contain multiple Namespaces. Namespaces can be nested and serve as containers for Namespaces, Tables and Views. Using the <code>/catalog</code> API, a Namespace cannot be dropped unless it is empty. A cascade-drop API is added in one of the next releases as part of the <code>/management</code> API.</p>"}, {"location": "docs/latest/docs/concepts/#tables-views", "title": "Tables &amp; Views", "text": "<p>Each Namespace can contain multiple Tables and Views. When creating new Tables and Views, we recommend to not specify the <code>location</code> explicitly. If locations are specified explicitly, the location must be a valid sub location of the <code>storage-profile</code> of the Warehouse - this is validated by Lakekeeper upon creation. Lakekeeper also ensures that there are no Tables or Views that use a parent- or sub-folder as their <code>location</code> and that the location is empty on creation. These checks are required to ensure that no data is leaked via vended-credentials.</p>"}, {"location": "docs/latest/docs/concepts/#users", "title": "Users", "text": "<p>Lakekeeper is no Identity Provider. The identities of users are exclusively managed via an external Identity Provider to ensure compliance with basic security standards. Lakekeeper does not store any Password / Certificates / API Keys or any other secret that grants access to data for users. Instead, we only store Name, Email and type of users with the sole purpose of providing a convenient search while assigning privileges.</p> <p>Users can be provisioned to Lakekeeper by either of the following endpoints:</p> <ul> <li>Explicit user creation via the POST <code>/management/user</code> endpoint. This endpoint is called automatically by the UI upon login. Thus, users are \"searchable\" after their first login to the UI.</li> <li>Implicit on-the-fly creation when calling GET <code>/catalog/v1/config</code>. This can be used to register technical users simply by connecting to the Lakekeeper with your favorite tool (i.e. Spark). The initial connection will probably fail because privileges are missing to use this endpoint, but the user is provisioned anyway so that privileges can be assigned before re-connecting.</li> </ul>"}, {"location": "docs/latest/docs/concepts/#roles", "title": "Roles", "text": "<p>Projects can contain multiple Roles, allowing Roles to be reused in all Warehouses within the Project. Roles can be nested arbitrarily, meaning that a role can contain other roles within it. Roles can be provisioned automatically using the <code>/management/v1/role</code> endpoint or manually created via the UI. We are looking into SCIM support to simplify role provisioning. Please consider upvoting the corresponding Github Issue if this would be of interest to you.</p>"}, {"location": "docs/latest/docs/concepts/#dropping-tables", "title": "Dropping Tables", "text": "<p>Currently all tables stored in Lakekeeper are assumed to be managed by Lakekeeper. The concept of \"external\" tables will follow in a later release. When managed tables are dropped, Lakekeeper defaults to setting <code>purgeRequested</code> parameter of the <code>dropTable</code> endpoint to true unless explicitly set to false. Currently most query engines do not set this flag, which defaults to enabling purge. If purge is enabled for a drop, all files of the table are removed.</p>"}, {"location": "docs/latest/docs/concepts/#soft-deletion", "title": "Soft Deletion", "text": "<p>In Lakekeeper, warehouses can enable soft deletion. If soft deletion is enabled for a warehouse, when a table or view is dropped, it is not immediately deleted from the catalog. Instead, it is marked as dropped and a job for its cleanup is scheduled. The table is then deleted after the warehouse specific expiration delay has passed. This will allow for a recovery of tables that have been dropped by accident. \"Undropping\" a table is only possible if soft-deletes are enabled for a Warehouse. The expiration delay is determined at the time of dropping the table, that means changing the delay in the warehouse settings will only affect newly dropped tables. If you want \"soft-deleted\" tables to be gone faster, undrop the tables, change the expiration delay and re-drop them. </p>"}, {"location": "docs/latest/docs/concepts/#migration", "title": "Migration", "text": "<p>Migration is a crucial step that must be performed before starting the Lakekeeper. It initializes the persistent backend storage and, if enabled, the authorization system. </p> <p>For each Lakekeeper update, migration must be executed before the <code>serve</code> command can be called. This ensures that all necessary updates and configurations are applied to the system. It is possible to skip Lakekeeper versions during migration.</p>"}, {"location": "docs/latest/docs/configuration/", "title": "Configuration", "text": "<p>Lakekeeper is configured via environment variables. Settings listed in this page are shared between all projects and warehouses. Previous to Lakekeeper Version <code>0.5.0</code> please prefix all environment variables with <code>ICEBERG_REST__</code> instead of <code>LAKEKEEPER__</code>.</p> <p>For most deployments, we recommend to set at least the following variables: <code>LAKEKEEPER__BASE_URI</code>, <code>LAKEKEEPER__PG_DATABASE_URL_READ</code>, <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code>, <code>LAKEKEEPER__PG_ENCRYPTION_KEY</code>.</p>"}, {"location": "docs/latest/docs/configuration/#general", "title": "General", "text": "Variable Example Description <code>LAKEKEEPER__BASE_URI</code> <code>https://example.com:8181</code> Base URL where the catalog is externally reachable. Default: <code>https://localhost:8181</code> <code>LAKEKEEPER__ENABLE_DEFAULT_PROJECT</code> <code>true</code> If <code>true</code>, the NIL Project ID (\"00000000-0000-0000-0000-000000000000\") is used as a default if the user does not specify a project when connecting. This option is enabled by default, which we recommend for all single-project (single-tenant) setups. Default: <code>true</code>. <code>LAKEKEEPER__RESERVED_NAMESPACES</code> <code>system,examples,information_schema</code> Reserved Namespaces that cannot be created via the REST interface <code>LAKEKEEPER__METRICS_PORT</code> <code>9000</code> Port where the Prometheus metrics endpoint is reachable. Default: <code>9000</code> <code>LAKEKEEPER__LISTEN_PORT</code> <code>8181</code> Port the Lakekeeper listens on. Default: <code>8181</code> <code>LAKEKEEPER__SECRET_BACKEND</code> <code>postgres</code> The secret backend to use. If <code>kv2</code> (Hashicorp KV Version 2) is chosen, you need to provide additional parameters Default: <code>postgres</code>, one-of: [<code>postgres</code>, <code>kv2</code>] <code>LAKEKEEPER__ALLOW_ORIGIN</code> <code>*</code> A comma separated list of allowed origins for CORS."}, {"location": "docs/latest/docs/configuration/#persistence-store", "title": "Persistence Store", "text": "<p>Currently Lakekeeper supports only Postgres as a persistence store. You may either provide connection strings using <code>PG_DATABASE_URL_READ</code> or use the <code>PG_*</code> environment variables. Connection strings take precedence:</p> Variable Example Description <code>LAKEKEEPER__PG_DATABASE_URL_READ</code> <code>postgres://postgres:password@localhost:5432/iceberg</code> Postgres Database connection string used for reading. Defaults to <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code>. <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code> <code>postgres://postgres:password@localhost:5432/iceberg</code> Postgres Database connection string used for writing. <code>LAKEKEEPER__PG_ENCRYPTION_KEY</code> <code>This is unsafe, please set a proper key</code> If <code>LAKEKEEPER__SECRET_BACKEND=postgres</code>, this key is used to encrypt secrets. It is required to change this for production deployments. <code>LAKEKEEPER__PG_READ_POOL_CONNECTIONS</code> <code>10</code> Number of connections in the read pool <code>LAKEKEEPER__PG_WRITE_POOL_CONNECTIONS</code> <code>5</code> Number of connections in the write pool <code>LAKEKEEPER__PG_HOST_R</code> <code>localhost</code> Hostname for read operations. Defaults to <code>LAKEKEEPER__PG_HOST_W</code>. <code>LAKEKEEPER__PG_HOST_W</code> <code>localhost</code> Hostname for write operations <code>LAKEKEEPER__PG_PORT</code> <code>5432</code> Port number <code>LAKEKEEPER__PG_USER</code> <code>postgres</code> Username for authentication <code>LAKEKEEPER__PG_PASSWORD</code> <code>password</code> Password for authentication <code>LAKEKEEPER__PG_DATABASE</code> <code>iceberg</code> Database name <code>LAKEKEEPER__PG_SSL_MODE</code> <code>require</code> SSL mode (disable, allow, prefer, require) <code>LAKEKEEPER__PG_SSL_ROOT_CERT</code> <code>/path/to/root/cert</code> Path to SSL root certificate <code>LAKEKEEPER__PG_ENABLE_STATEMENT_LOGGING</code> <code>true</code> Enable SQL statement logging <code>LAKEKEEPER__PG_TEST_BEFORE_ACQUIRE</code> <code>true</code> Test connections before acquiring from the pool <code>LAKEKEEPER__PG_CONNECTION_MAX_LIFETIME</code> <code>1800</code> Maximum lifetime of connections in seconds"}, {"location": "docs/latest/docs/configuration/#vault-kv-version-2", "title": "Vault KV Version 2", "text": "<p>Configuration parameters if a Vault KV version 2 (i.e. Hashicorp Vault) compatible storage is used as a backend. Currently, we only support the <code>userpass</code> authentication method. Configuration may be passed as single values like <code>LAKEKEEPER__KV2__URL=http://vault.local</code> or as a compound value: <code>LAKEKEEPER__KV2='{url=\"http://localhost:1234\", user=\"test\", password=\"test\", secret_mount=\"secret\"}'</code></p> Variable Example Description <code>LAKEKEEPER__KV2__URL</code> <code>https://vault.local</code> URL of the KV2 backend <code>LAKEKEEPER__KV2__USER</code> <code>admin</code> Username to authenticate against the KV2 backend <code>LAKEKEEPER__KV2__PASSWORD</code> <code>password</code> Password to authenticate against the KV2 backend <code>LAKEKEEPER__KV2__SECRET_MOUNT</code> <code>kv/data/iceberg</code> Path to the secret mount in the KV2 backend"}, {"location": "docs/latest/docs/configuration/#task-queues", "title": "Task queues", "text": "<p>Lakekeeper uses task queues internally to remove soft-deleted tabulars and purge tabular files. The following global configuration options are available:</p> Variable Example Description <code>LAKEKEEPER__QUEUE_CONFIG__MAX_RETRIES</code> 5 Number of retries before a task is considered failed  Default: 5 <code>LAKEKEEPER__QUEUE_CONFIG__MAX_AGE</code> 3600 Amount of seconds before a task is considered stale and could be picked up by another worker. Default: 3600 <code>LAKEKEEPER__QUEUE_CONFIG__POLL_INTERVAL</code> 10 Amount of seconds between polling for new tasks. Default: 10"}, {"location": "docs/latest/docs/configuration/#nats", "title": "Nats", "text": "<p>Lakekeeper can publish change events to Nats (Kafka is coming soon). The following configuration options are available:</p> Variable Example Description <code>LAKEKEEPER__NATS_ADDRESS</code> <code>nats://localhost:4222</code> The URL of the NATS server to connect to <code>LAKEKEEPER__NATS_TOPIC</code> <code>iceberg</code> The subject to publish events to <code>LAKEKEEPER__NATS_USER</code> <code>test-user</code> User to authenticate against nats, needs <code>LAKEKEEPER__NATS_PASSWORD</code> <code>LAKEKEEPER__NATS_PASSWORD</code> <code>test-password</code> Password to authenticate against nats, needs <code>LAKEKEEPER__NATS_USER</code> <code>LAKEKEEPER__NATS_CREDS_FILE</code> <code>/path/to/file.creds</code> Path to a file containing nats credentials <code>LAKEKEEPER__NATS_TOKEN</code> <code>xyz</code> Nats token to use for authentication"}, {"location": "docs/latest/docs/configuration/#authentication", "title": "Authentication", "text": "<p>To prohibit unwanted access to data, we recommend to enable Authentication.</p> <p>Authentication is enabled if:</p> <ul> <li><code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is set OR</li> <li><code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code> is set to true</li> </ul> <p>External OpenID and Kubernetes Authentication can also be enabled together. If <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is specified, Lakekeeper will  verify access tokens against this provider. The provider must provide the <code>.well-known/openid-configuration</code> endpoint and the openid-configuration needs to have <code>jwks_uri</code> and <code>issuer</code> defined. </p> <p>Typical values for <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> are:</p> <ul> <li>Keycloak: <code>https://keycloak.local/realms/{your-realm}</code></li> <li>Entra-ID: <code>https://login.microsoftonline.com/{your-tenant-id-here}/v2.0/</code></li> </ul> <p>Please check the Authentication Guide for more details.</p> Variable Example Description <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> <code>https://keycloak.local/realms/{your-realm}</code> OpenID Provider URL. <code>LAKEKEEPER__OPENID_AUDIENCE</code> <code>the-client-id-of-my-app</code> If set, the <code>aud</code> of the provided token must match the value provided. Multiple allowed audiences can be provided as a comma separated list. <code>LAKEKEEPER__OPENID_ADDITIONAL_ISSUERS</code> <code>https://sts.windows.net/&lt;Tenant&gt;/</code> A comma separated list of additional issuers to trust. The issuer defined in the <code>issuer</code> field of the <code>.well-known/openid-configuration</code> is always trusted. <code>LAKEKEEPER__OPENID_ADDITIONAL_ISSUERS</code> has no effect if <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is not set. <code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code> true If true, kubernetes service accounts can authenticate to Lakekeeper. This option is compatible with <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> - multiple IdPs (OIDC and Kubernetes) can be enabled simultaneously."}, {"location": "docs/latest/docs/configuration/#authorization", "title": "Authorization", "text": "<p>Authorization is only effective if Authentication is enabled. Authorization must not be enabled after Lakekeeper has been bootstrapped! Please create a new Lakekeeper instance, bootstrap it with authorization enabled, and migrate your tables.</p> Variable Example Description <code>LAKEKEEPER__AUTHZ_BACKEND</code> <code>allowall</code> The authorization backend to use. If <code>openfga</code> is chosen, you need to provide additional parameters. The <code>allowall</code> backend disables authorization - authenticated users can access all endpoints. Default: <code>allowall</code>, one-of: [<code>openfga</code>, <code>allowall</code>] <code>LAKEKEEPER__OPENFGA__ENDPOINT</code> <code>http://localhost:35081</code> OpenFGA Endpoint (gRPC). <code>LAKEKEEPER__OPENFGA__STORE_NAME</code> <code>lakekeeper</code> The OpenFGA Store to use. Default: <code>lakekeeper</code> <code>LAKEKEEPER__OPENFGA__API_KEY</code> <code>my-api-key</code> The API Key used for Pre-shared key authentication to OpenFGA. If <code>LAKEKEEPER__OPENFGA__CLIENT_ID</code> is set, the API Key is ignored. If neither API Key nor Client ID is specified, no authentication is used. <code>LAKEKEEPER__OPENFGA__CLIENT_ID</code> <code>12345</code> The Client ID to use for Authenticating if OpenFGA is secured via OIDC. <code>LAKEKEEPER__OPENFGA__CLIENT_SECRET</code> <code>abcd</code> Client Secret for the Client ID. <code>LAKEKEEPER__OPENFGA__TOKEN_ENDPOINT</code> <code>https://keycloak.example.com/realms/master/protocol/openid-connect/token</code> Token Endpoint to use when exchanging client credentials for an access token for OpenFGA. Required if Client ID is set"}, {"location": "docs/latest/docs/configuration/#ui", "title": "UI", "text": "<p>When using the built-in UI which is hosted as part of the Lakekeeper binary, most values are pre-set with the corresponding values of Lakekeeper itself. Customization is typically required if Authentication is enabled. Please check the Authentication guide for more information.</p> Variable Example Description <code>LAKEKEEPER__UI__OPENID_PROVIDER_URI</code> <code>https://keycloak.local/realms/{your-realm}</code> OpenID provider URI used for login in the UI. Defaults to <code>LAKEKEEPER__OPENID_PROVIDER_URI</code>. Set this only if the IdP is reachable under a different URI from the users browser and lakekeeper. <code>LAKEKEEPER__UI__OPENID_CLIENT_ID</code> <code>lakekeeper-ui</code> Client ID to use for the Authorization Code Flow of the UI. Required if Authentication is enabled. Defaults to <code>lakekeeper</code> <code>LAKEKEEPER__UI__OPENID_REDIRECT_PATH</code> <code>/callback</code> Path where the UI receives the callback including the tokens from the users browser. Defaults to: <code>/callback</code> <code>LAKEKEEPER__UI__OPENID_SCOPE</code> <code>openid email</code> Scopes to request from the IdP. Defaults to <code>openid profile email</code>. <code>LAKEKEEPER__UI__OPENID_RESOURCE</code> <code>lakekeeper-api</code> Resources to request from the IdP. If not specified, the <code>resource</code> field is omitted (default). <code>LAKEKEEPER__UI__OPENID_POST_LOGOUT_REDIRECT_PATH</code> <code>/logout</code> Path the UI calls when users are logged out from the IdP. Defaults to <code>/logout</code>"}, {"location": "docs/latest/docs/configuration/#ssl-dependencies", "title": "SSL Dependencies", "text": "<p>You may be running Lakekeeper in your own environment which uses self-signed certificates for e.g. Minio. Lakekeeper is built with reqwest's <code>rustls-tls-native-roots</code> feature activated, this means <code>SSL_CERT_FILE</code> and <code>SSL_CERT_DIR</code> environment variables are respected. If both are not set, the system's default CA store is used. If you want to use a custom CA store, set <code>SSL_CERT_FILE</code> to the path of the CA file or <code>SSL_CERT_DIR</code> to the path of the CA directory. The certificate used by the server cannot be a CA. It needs to be an end entity certificate, else you may run into <code>CaUsedAsEndEntity</code> errors.</p>"}, {"location": "docs/latest/docs/customize/", "title": "Customize", "text": "<p>As Customizability is one of the core features we are missing in other IRC implementations, we try to do things differently. The core implementation of this crate is based on four modules that back the <code>axum</code> service router:</p> <ul> <li><code>Catalog</code> is the interface to the DB backend where Warehouses, Namespaces, Tables and other entities are managed.</li> <li><code>SecretStore</code> is the interface to a secure storage for secrets.</li> <li><code>Authorizer</code> is the interface to the permission system used by Lakekeeper. It may expose its own APIs.</li> <li><code>EventPublisher</code> is the interface to message queues to send change events to.</li> <li><code>ContractValidator</code> allows an external system to prohibit changes to tables if, for example, data contracts are violated</li> <li><code>TaskQueue</code> is the interface to the task store, used to schedule tasks like soft-deletes</li> </ul> <p>All components come pre-implemented, however we encourage you to write custom implementations, for example to seamlessly grant access to tables via your companies Data Governance solution, or publish events to your very important messaging service.</p>"}, {"location": "docs/latest/docs/developer-guide/", "title": "Developer Guide", "text": "<p>All commits to main should go through a PR. CI checks should pass before merging the PR. Before merge commits are squashed. PR titles should follow Conventional Commits.</p>"}, {"location": "docs/latest/docs/developer-guide/#foundation-cla", "title": "Foundation &amp; CLA", "text": "<p>We hate red tape. Currently all committers need to sign the CLA in github. To ensure the future of Lakekeeper, we want to donate the project to a foundation. We are not sure yet if this is going to be Apache, Linux, a Lakekeeper foundation or something else. Currently we prefer to spent our time on adding cool new features to Lakekeeper, but we will revisit this topic during 2026.</p>"}, {"location": "docs/latest/docs/developer-guide/#quickstart", "title": "Quickstart", "text": "<pre><code># start postgres\ndocker run -d --name postgres-15 -p 5432:5432 -e POSTGRES_PASSWORD=postgres postgres:15\n# set envs\necho 'export DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres' &gt; .env\necho 'export ICEBERG_REST__PG_ENCRYPTION_KEY=\"abc\"' &gt;&gt; .env\necho 'export ICEBERG_REST__PG_DATABASE_URL_READ=\"postgresql://postgres:postgres@localhost/postgres\"' &gt;&gt; .env\necho 'export ICEBERG_REST__PG_DATABASE_URL_WRITE=\"postgresql://postgres:postgres@localhost/postgres\"' &gt;&gt; .env\nsource .env\n\n# migrate db\ncd crates/iceberg-catalog\nsqlx database create &amp;&amp; sqlx migrate run\ncd ../..\n\n# run tests\ncargo test --all-features --all-targets\n\n# run clippy\ncargo clippy --all-features --all-targets\n</code></pre> <p>This quickstart does not run tests against cloud-storage providers or KV2. For that, please refer to the sections below.</p>"}, {"location": "docs/latest/docs/developer-guide/#developing-with-docker-compose", "title": "Developing with docker compose", "text": "<p>The following shell snippet will start a full development environment including the catalog plus its dependencies and a jupyter server with spark. The iceberg-catalog and its migrations will be built from source. This can be useful for development and testing.</p> <pre><code>$ cd examples\n$ docker-compose -f docker-compose.yaml -f docker-compose-latest.yaml up -d --build\n</code></pre> <p>You may then head to <code>localhost:8888</code> and try out one of the notebooks.</p>"}, {"location": "docs/latest/docs/developer-guide/#working-with-sqlx", "title": "Working with SQLx", "text": "<p>This crate uses sqlx. For development and compilation a Postgres Database is required. You can use Docker to launch one.:</p> <p><pre><code>docker run -d --name postgres-15 -p 5432:5432 -e POSTGRES_PASSWORD=postgres postgres:15\n</code></pre> The <code>crates/iceberg-catalog</code> folder contains a <code>.env.sample</code> File. Copy this file to <code>.env</code> and add your database credentials if they differ.</p> <p>Run:</p> <pre><code>sqlx database create\nsqlx migrate run\n</code></pre>"}, {"location": "docs/latest/docs/developer-guide/#kv2-vault", "title": "KV2 / Vault", "text": "<p>This catalog supports KV2 as backend for secrets. Tests for KV2 are disabled by default. To enable them, you need to run the following commands:</p> <pre><code>docker run -d -p 8200:8200 --cap-add=IPC_LOCK -e 'VAULT_DEV_ROOT_TOKEN_ID=myroot' -e 'VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200' hashicorp/vault\n\n# append some more env vars to the .env file, it should already have PG related entries defined above.\n\n# this will enable the KV2 tests\necho 'export TEST_KV2=1' &gt;&gt; .env\n# the values below configure KV2\necho 'export ICEBERG_REST__KV2__URL=\"http://localhost:8200\"' &gt;&gt; .env\necho 'export ICEBERG_REST__KV2__USER=\"test\"' &gt;&gt; .env\necho 'export ICEBERG_REST__KV2__PASSWORD=\"test\"' &gt;&gt; .env\necho 'export ICEBERG_REST__KV2__SECRET_MOUNT=\"secret\"' &gt;&gt; .env\n\nsource .env\n# setup vault\n./tests/vault-setup.sh http://localhost:8200\n\ncargo test --all-features --all-targets\n</code></pre>"}, {"location": "docs/latest/docs/developer-guide/#test-cloud-storage-profiles", "title": "Test cloud storage profiles", "text": "<p>Currently, we're not aware of a good way of testing cloud storage integration against local deployments. That means, in order to test against AWS S3, GCS and ADLS Gen2, you need to set the following environment variables. For more information take a look at the Storage Guide. A sample <code>.env</code> could look like this:</p> <pre><code># TEST_AZURE=&lt;some-value&gt; controls a proc macro which either includes or excludes the azure tests\n# if you compiled without TEST_AZURE, you'll have to change a file or do a cargo clean before rerunning tests. The same applies for the TEST_AWS and TEST_MINIO env vars.\nexport TEST_AZURE=1\nexport AZURE_TENANT_ID=&lt;your tenant id&gt;\nexport AZURE_CLIENT_ID=&lt;your entra id app registration client id&gt;\nexport AZURE_CLIENT_SECRET=&lt;your entra id app registration client secret&gt;\nexport AZURE_STORAGE_ACCOUNT_NAME=&lt;your azure storage account name&gt;\nexport AZURE_STORAGE_FILESYSTEM=&lt;your azure adls filesystem name&gt;\n\nexport TEST_AWS=1\nexport AWS_S3_BUCKET=&lt;your aws s3 bucket&gt;\nexport AWS_S3_REGION=&lt;your aws s3 region&gt;\n# replace with actual values\nexport AWS_S3_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE\nexport AWS_S3_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nexport AWS_S3_STS_ROLE_ARN=arn:aws:iam::123456789012:role/role-name\n\n# the values below should work with the default minio in our docker-compose\nexport TEST_MINIO=1\nexport LAKEKEEPER_TEST__S3_BUCKET=tests\nexport LAKEKEEPER_TEST__S3_REGION=local\nexport LAKEKEEPER_TEST__S3_ACCESS_KEY=minio-root-user\nexport LAKEKEEPER_TEST__S3_SECRET_KEY=minio-root-password\nexport LAKEKEEPER_TEST__S3_ENDPOINT=http://localhost:9000\n</code></pre> <p>You may then run a test via:</p> <pre><code>source .example.env-from-above\ncargo test service::storage::s3::test::aws::test_can_validate\n</code></pre>"}, {"location": "docs/latest/docs/developer-guide/#running-integration-test", "title": "Running integration test", "text": "<p>Please check the Integration Test Docs.</p>"}, {"location": "docs/latest/docs/developer-guide/#extending-authz", "title": "Extending Authz", "text": "<p>When adding a new endpoint, you may need to extend the authorization model. Please check the Authorization Docs for more information. For openfga, you'll have to perform the following steps:</p> <ol> <li>extend the respective enum in <code>crate::service::authz</code> by adding the new action, e.g. <code>crate::service::authz::CatalogViewAction::CanUndrop</code></li> <li>add the relation to <code>crate::service::authz::implementations::openfga::relations</code>, e.g. add <code>ViewRelation::CanUndrop</code></li> <li>add the mapping from the <code>implementations</code> type to the <code>service</code> type in <code>openfga::relations</code>, e.g. <code>CatalogViewAction::CanUndrop =&gt; ViewRelation::CanUndrop</code></li> <li>create a new authz schema version by copying the latest existing one, e.g. <code>authz/openfga/v1/</code> to <code>authz/openfga/v2/</code></li> <li>apply your changes, e.g. add <code>define can_undrop: modify</code> to the <code>view</code> type in <code>authz/openfga/v2/schema.fga</code></li> <li>create a diff between the old and new schema via <code>diff -u authz/openfga/v1/schema.fga authz/openfga/v2/schema.fga &gt; authz/openfga/v2/changed.diff</code> to help your reviewers</li> <li>regenerate <code>schema.json</code> via <code>./fga model transform --file authz/openfga/v2/schema.fga &gt; authz/openfga/v2/schema.json</code> (download the <code>fga</code> binary from the OpenFGA repo)</li> <li>Head to <code>crate::service::authz::implementations::openfga::models.rs</code>, extend <code>CollaborationModels</code> with a field for your version, e.g., <code>v2</code> and then add your new model version on top of the file, like: <pre><code>const V2_MODEL: &amp;str = include_str!(\"../../../../../../../authz/openfga/v2/schema.json\");\n\nstatic MODEL: LazyLock&lt;CollaborationModels&gt; = LazyLock::new(|| CollaborationModels {\n    v1: serde_json::from_str(V1_MODEL).expect(\"Failed to parse OpenFGA model V1 as JSON\"),\n    // this is your added model below\n    v2: serde_json::from_str(V2_MODEL).expect(\"Failed to parse OpenFGA model V2 as JSON\"),\n});\n</code></pre></li> <li>set your model as the active model like: <code>const ACTIVE_MODEL: ModelVersion = ModelVersion::V2;</code></li> <li>implement the migration in <code>crate::service::authz::implementations::openfga::migrations::migrate</code> like: <pre><code>match model_version {\n    ModelVersion::V1 =&gt; {\n    // no migration to be done, we start at v1\n    }\n    ModelVersion::V2 =&gt; v2::migrate(client, &amp;store).await,\n}\n</code></pre></li> </ol>"}, {"location": "docs/latest/docs/opa/", "title": "Open Policy Agent (OPA)", "text": "<p>Lakekeeper's Open Policy Agent bridge enables compute engines that support fine-grained access control via Open Policy Agent (OPA) as authorization engine to respect privileges in Lakekeeper. We have also prepared a self-contained Docker Compose Example to get started quickly.</p> <p>Let's imagine we have a trusted multi-user query engine such as trino, in addition to single-user query engines like pyiceberg or daft in Jupyter Notebooks. Managing permissions in trino independently of the other tools is not an option, as we do not want to duplicate permissions across query engines. Our multi-user query engine has two options:</p> <ol> <li>Catalog enforces permissions: The engine contacts the Catalog on behalf of the user. To achieve this, the engine must be able to impersonate the user for the catalog application. In OAuth2 settings, this can be accomplished through downscoping tokens or other forms of Token Exchange.</li> <li>Compute enforces permissions: After contacting the catalog with a god-like \"I can do everything!\" user (e.g. <code>project_admin</code>), the query engine then contacts the permission system, retrieves, and enforces those permissions. Note that this requires the engine to run in a trusted environment, as whoever has root access to the engine also has access to the god-like credential.</li> </ol> <p>The Lakekeeper OPA Bridge enables solution 2, by exposing all permissions in Lakekeeper via OPA. The Bridge itself is a collection of OPA files in the <code>authz/opa-bridge</code> folder of the Lakekeeper GitHub repository.</p> <p>The bridge also comes with a translation layer for trino to translate trino to Lakekeeper permissions and thus serve trinos OPA queries. Currently trino is the only iceberg query engine we are aware of that is flexible enough to honor external permissions via OPA. Please let us know if you are aware of other engines, so that we can add support.</p>"}, {"location": "docs/latest/docs/opa/#configuration", "title": "Configuration", "text": "<p>Lakekeeper's OPA bridge needs to access the permissions API of Lakekeeper. As such, we need a technical user for OPA (Client ID, Client Secret) that OPA can use to authenticate to Lakekeeper. Please check the Authentication guide for more information on how to create technical users. We recommend to use the same user for creating the catalog in trino to ensure same access. In most scenarios, this user should have the <code>project_admin</code> role.</p> <p>The plugin can be customized by either editing the <code>configuration.rego</code> file or by setting environment variables. By editing the <code>configuration.rego</code> files you can also easily connect multiple lakekeeper instance to the same trino instance. Please find all available configuration options explained in the file.</p> <p>If configuration is done via environment variables, the following settings are available:</p> Variable Example Description <code>LAKEKEEPER_URL</code> <code>https://lakekeeper.example.com</code> URL where lakekeeper is externally reachable. Default: <code>https://localhost:8181</code> <code>LAKEKEEPER_TOKEN_ENDPOINT</code> <code>http://keycloak:8080/realms/iceberg/protocol/openid-connect/token</code> Token endpoint of the IdP used to secure Lakekeeper. This endpoint is used to exchange OPAs client credentials for an access token. <code>LAKEKEEPER_CLIENT_ID</code> <code>trino</code> Client ID used by OPA to access Lakekeeper's permissions API. <code>LAKEKEEPER_CLIENT_SECRET</code> <code>abcd</code> Client Secret for the Client ID. <code>LAKEKEEPER_SCOPE</code> <code>lakekeeper</code> Scopes to request from the IdP. Defaults to <code>lakekeeper</code>. Please check the Authentication Guide for setup. <p>All above mentioned configuration options refer to a specific Lakekeeper instance. What is missing is a mapping of trino catalogs to Lakekeeper warehouses. By default we support 4 catalogs in trino, but more can easily be added in the <code>configuration.rego</code>.</p> Variable Example Description <code>TRINO_DEV_CATALOG_NAME</code> <code>dev</code> Name of the development catalog in trino. Default: <code>dev</code> <code>LAKEKEEPER_DEV_WAREHOUSE</code> <code>development</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_DEV_CATALOG_NAME</code> catalog in trino. Default: <code>development</code> <code>TRINO_PROD_CATALOG_NAME</code> <code>prod</code> Name of the development catalog in trino. Default: <code>prod</code> <code>LAKEKEEPER_PROD_WAREHOUSE</code> <code>production</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_PROD_CATALOG_NAME</code> catalog in trino. Default: <code>production</code> <code>TRINO_DEMO_CATALOG_NAME</code> <code>demo</code> Name of the development catalog in trino. Default: <code>prod</code> <code>LAKEKEEPER_DEMO_WAREHOUSE</code> <code>demo</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_DEMO_CATALOG_NAME</code> catalog in trino. Default: <code>demo</code> <code>TRINO_LAKEKEEPER_CATALOG_NAME</code> <code>lakekeeper</code> Name of the development catalog in trino. Default: <code>lakekeeper</code> <code>LAKEKEEPER_LAKEKEEPER_WAREHOUSE</code> <code>lakekeeper</code> Name of the development warehouse in lakekeeper that corresponds to the <code>TRINO_LAKEKEEPER_CATALOG_NAME</code> catalog in trino. Default: <code>production</code> <p>When OPA is running and configured, set the following configurations for trino in <code>access-control.properties</code>: <pre><code>access-control.name=opa\nopa.policy.uri=http://&lt;URL where OPA is reachable&gt;/v1/data/trino/allow\nopa.log-requests=true\nopa.log-responses=true\nopa.policy.batched-uri=http://&lt;URL where OPA is reachable&gt;/v1/data/trino/batch\n</code></pre></p> <p>A full self-contained example is available on GitHub.</p>"}, {"location": "docs/latest/docs/production/", "title": "Production Checklist", "text": "<p>Lakekeeper is the heart of your data platform and needs to integrate deeply with your existing infrastructure such as IdPs. The easiest way to get Lakekeeper to production is our enterprise support. Please find more information on our commercial offerings at lakekeeper.io</p> <p>Please find following some general recommendations for productive setups:</p> <ul> <li>Use an external high-available database as a catalog backend. We recommend using a managed service in your preferred Cloud or host a high available cluster on Kubernetes yourself using your preferred operator. We are using the amazing CloudNativePG internally. Make sure the Database is backed-up regularly.</li> <li>Ensure sure both <code>LAKEKEEPER__PG_DATABASE_URL_READ</code> and <code>LAKEKEEPER__PG_DATABASE_URL_WRITE</code> are set for ideal load distribution. Most postgres deployments specify separate URLs for reading and writing to channel writes to the master while distributing reads across replicas.</li> <li>For high-available setups, ensure that multiple Lakekeeper instances are running on different nodes. We recommend our helm chart for production deployments.</li> <li>Ensure that Authentication is enabled, typically by setting <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> and / or <code>LAKEKEEPER__ENABLE_KUBERNETES_AUTHENTICATION</code>. Check our Authentication Guide for more information.</li> <li>If <code>LAKEKEEPER__OPENID_PROVIDER_URI</code> is set, we recommend to set <code>LAKEKEEPER__OPENID_AUDIENCE</code> as well.</li> <li>If Authorization is desired, follow our Authorization Guide. Ensure that OpenFGA is hosted in close proximity to Lakekeeper - ideally on the same VM or Kubernetes node. In our Helm-Chart we use <code>PodAffinity</code> to achieve this.</li> <li>If the default Postgres secret backend is used, ensure that <code>LAKEKEEPER__PG_ENCRYPTION_KEY</code> is set to a long random string.</li> <li>Ensure that all Warehouses use distinct storage locations / prefixes and distinct credentials that only grant access to the prefix used for a Warehouse.</li> <li>Ensure that SSL / TLS is enabled. Lakekeeper does not terminate connections natively. Please use a reverse proxy like Nginx or Envoy to secure the connection to Lakekeeper. On Kubernetes, any Ingress controller can be used. For high-availability, failover should be handled by the reverse proxy. Lakekeeper exposes a <code>/health</code> endpoint that can be used to determine its current status. If you are using our helm-chart, probes are already built-in.</li> <li>If a trusted query engine, such as a centrally managed trino, uses Lakekeeper's OPA bridge, ensure that no users have root access to trino or OPA as those contain credentials to Lakekeeper with very high permissions.</li> </ul>"}, {"location": "docs/latest/docs/storage/", "title": "Storage", "text": "<p>Storage in Lakekeeper is bound to a Warehouse. Each Warehouse stores data in a location defined by a <code>StorageProfile</code> attached to it.</p> <p>Currently, we support the following storages:</p> <ul> <li>S3 (tested with AWS &amp; Minio)</li> <li>Azure Data Lake Storage Gen 2</li> <li>Google Cloud Storage</li> </ul> <p>When creating a Warehouse or updating storage information, Lakekeeper validates the configuration.</p>"}, {"location": "docs/latest/docs/storage/#s3", "title": "S3", "text": "<p>We support remote signing and vended-credentials with Minio &amp; AWS. Both provide a secure way to access data on S3:</p> <ul> <li>Remote Signing: The client prepares an S3 request and sends its headers to the sign endpoint of Lakekeeper. Lakekeeper checks if the request is allowed, if so, it signs the request with its own credentials, creating additional headers during the process. These additional signing headers are returned to the client, which then contacts S3 directly to perform the operation on files.</li> <li>Vended Credentials: Lakekeeper uses the \"STS\" Endpoint of S3 to generate temporary credentials which are then returned to clients.</li> </ul> <p>Remote signing works natively with all S3 storages that support the default <code>AWS Signature Version 4</code>. This includes almost all S3 solutions on the market today, including Minio, Rook Ceph and others. Vended credentials in turn depend on an additional \"STS\" Endpoint, that is not supported by all S3 implementations. We run our integration tests for vended credentials against Minio and AWS. We recommend to setup vended credentials for all supported stores, remote signing is not supported by all clients.</p>"}, {"location": "docs/latest/docs/storage/#aws", "title": "AWS", "text": "<p>First create a new S3 bucket for the warehouse. Buckets can be re-used for multiple Warehouses as long as the <code>key-prefix</code> is different. We recommend to block all public access.</p> <p>Secondly we need to create an AWS role that can access and delegate access to the bucket. We start by creating a new Policy that allows access to data in the bucket. We call this policy <code>LakekeeperWarehouseDev</code>:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"ListBuckets\",\n            \"Action\": [\n                \"s3:ListAllMyBuckets\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Effect\": \"Allow\",\n            \"Resource\": [\n                \"arn:aws:s3:::*\"\n            ]\n        },\n        {\n            \"Sid\": \"ListBucketContent\",\n            \"Action\": [\n                \"s3:ListBucket\"\n            ],\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:s3:::lakekeeper-aws-demo\"\n        },\n        {\n            \"Sid\": \"DataAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::lakekeeper-aws-demo/*\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>Now create a new user, we call the user <code>LakekeeperWarehouseDev</code>, and attach the previously created policy. When the user is created, click on \"Security credentials\" and \"Create access key\". Note down the access key and secret key for later use.</p> <p>We are done if we only rely on remote signing. For vended credentials, we need to perform one more step. Create a new role that we call <code>LakekeeperWarehouseDevRole</code>. This role needs to be trusted by the user, which is achieved via with the following trust policy: <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"TrustLakekeeperWarehouseDev\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::&lt;aws-account-id&gt;:user/LakekeeperWarehouseDev\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n</code></pre></p> <p>Also attach the <code>LakekeeperWarehouseDev</code> policy created earlier.</p> <p>We are now ready to create the Warehouse via the UI or REST-API using the following values (make sure to replace everything in <code>&lt;&gt;</code>):</p> <pre><code>{\n    \"warehouse-name\": \"aws_docs\",\n    \"storage-credential\": {\n        \"type\": \"s3\",\n        \"aws-access-key-id\": \"&lt;Access Key of the created user&gt;\",\n        \"aws-secret-access-key\": \"&lt;Secret Key of the created user&gt;\",\n        \"credential-type\": \"access-key\"\n    },\n    \"storage-profile\": {\n        \"type\": \"s3\",\n        \"bucket\": \"&lt;name of the bucket&gt;\",\n        \"region\": \"&lt;region of the bucket&gt;\",\n        \"sts-enabled\": true,\n        \"flavor\": \"aws\",\n        \"key-prefix\": \"lakekeeper-dev-warehouse\",\n        \"sts-role-arn\": \"arn:aws:iam::&lt;aws account id&gt;:role/LakekeeperWarehouseDevRole\"\n    },\n    \"delete-profile\": {\n        \"type\": \"hard\"\n    }\n}\n</code></pre>"}, {"location": "docs/latest/docs/storage/#s3-compatible", "title": "S3 Compatible", "text": "<p>Unlike for AWS, we do not need any special trust-setup for vended credentials / STS with most S3 compatible solutions like Minio. Instead, we just need a bucket and an access key / secret key combination that is able to read and write from it. If <code>sts-role-arn</code> is provided, it is ignored. Make sure to select <code>flavor</code> to have the value <code>s3-compat</code>! This setting should work for most self-hosted S3 solutions.</p> <p>An warehouse create call could look like this:</p> <pre><code>{\n    \"warehouse-name\": \"minio_dev\",\n    \"storage-credential\": {\n        \"type\": \"s3\",\n        \"aws-access-key-id\": \"&lt;Access Key of the created user&gt;\",\n        \"aws-secret-access-key\": \"&lt;Secret Key of the created user&gt;\",\n        \"credential-type\": \"access-key\"\n    },\n    \"storage-profile\": {\n        \"type\": \"s3\",\n        \"bucket\": \"&lt;name of the bucket&gt;\",\n        \"region\": \"local-01\",\n        \"sts-enabled\": true,\n        \"flavor\": \"s3-compat\",\n        \"key-prefix\": \"lakekeeper-dev-warehouse\",\n    },\n    \"delete-profile\": {\n        \"type\": \"hard\"\n    }\n}\n</code></pre>"}, {"location": "docs/latest/docs/storage/#azure-data-lake-storage-gen-2", "title": "Azure Data Lake Storage Gen 2", "text": "<p>To add a Warehouse backed by ADLS, we need two Azure objects: The Storage Account itself and an App Registration which Lakekeeper can use to access it and delegate access to compute engines.</p> <p>Lets start by creating a new \"App Registration\":</p> <ol> <li>Create a new \"App Registration\"<ul> <li>Name: choose any, for this example we choose <code>Lakekeeper Warehouse (Development)</code></li> <li>Redirect URI: Leave empty</li> </ul> </li> <li>When the App Registration is created, select \"Manage\" -&gt; \"Certificates &amp; secrets\" and create a \"New client secret\". Note down the secrets \"Value\".</li> <li>In the \"Overview\" page of the \"App Registration\" note down the <code>Application (client) ID</code> and the <code>Directory (tenant) ID</code>.</li> </ol> <p>Next, we create a new Storage Account. Make sure to select \"Enable hierarchical namespace\" in the \"Advanced\" section. For existing Storage Accounts make sure \"Hierarchical namespace: Enabled\" is shown in the \"Overview\" page. There are no specific requirements otherwise. Note down the name of the storage account. When the storage account is created, we need to grant the correct permissions to the \"App Registration\" and create the filesystem / container where the data is stored:</p> <ol> <li>Open the Storage Account and select \"Data storage\" -&gt; Containers. Add a new Container, we call it <code>warehouse-dev</code>.</li> <li>Next, select \"Access Control (IAM)\" in the left menu and \"Add role assignment\". Grant the <code>Storage Blob Data Contributor</code> and <code>Storage Blob Delegator</code> roles to the <code>Lakekeeper Warehouse (Development)</code> App Registration that we previously created.</li> </ol> <p>We are now ready to create the Warehouse via the UI or the REST API. Use the following information:</p> <ul> <li>client-id: The <code>Application (client) ID</code> of the <code>Lakekeeper Warehouse (Development)</code> App Registration.</li> <li>client-secret: The \"Value\" of the client secret that we noted down previously.</li> <li>tenant-id: The <code>Directory (tenant) ID</code> from the Applications Overview page.</li> <li>account-name: Name of the Storage Account</li> <li>filesystem: Name of the container (that Azure also calls filesystem) previously created. In our example its <code>warehouse-dev</code>.</li> </ul> <p>A POST request to <code>/management/v1/warehouse</code> would expects the following body:</p> <pre><code>{\n  \"warehouse-name\": \"azure_dev\",\n  \"delete-profile\": { \"type\": \"hard\" },\n  \"storage-credential\":\n    {\n      \"client-id\": \"...\",\n      \"client-secret\": \"...\",\n      \"credential-type\": \"client-credentials\",\n      \"tenant-id\": \"...\",\n      \"type\": \"az\",\n    },\n  \"storage-profile\":\n    {\n      \"account-name\": \"...\",\n      \"filesystem\": \"warehouse-dev\",\n      \"type\": \"adls\",\n    },\n}\n</code></pre>"}, {"location": "docs/latest/docs/storage/#gcs", "title": "GCS", "text": "<p>For GCS, the used bucket needs to disable hierarchical namespaces and should have the storage admin role.</p> <p>A sample storage profile could look like this.</p> <pre><code>{\n  \"warehouse-name\": \"gcs_dev\",\n  \"storage-profile\": {\n    \"type\": \"gcs\",\n    \"bucket\": \"...\",\n    \"key-prefix\": \"...\"\n  },\n  \"storage-credential\": {\n    \"type\": \"gcs\",\n    \"credential-type\": \"service-account-key\",\n    \"key\": {\n      \"type\": \"service_account\",\n      \"project_id\": \"example-project-1234\",\n      \"private_key_id\": \"....\",\n      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n.....\\n-----END PRIVATE KEY-----\\n\",\n      \"client_email\": \"abc@example-project-1234.iam.gserviceaccount.com\",\n      \"client_id\": \"123456789012345678901\",\n      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/abc%example-project-1234.iam.gserviceaccount.com\",\n      \"universe_domain\": \"googleapis.com\"\n    }\n  }\n}\n</code></pre>"}]}